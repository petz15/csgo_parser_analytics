{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52cc9eb4",
   "metadata": {},
   "source": [
    "# Testing alternatives to the CSF function\n",
    " also testing some regressions and parametric distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf6e1f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries - Enhanced for Statistical Analysis\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "# Set Up Database Connection\n",
    "# Replace the placeholders with your actual database credentials\n",
    "DB_CONFIG = {\n",
    "    \"dbname\": \"csgo_parsed\",\n",
    "    \"user\": \"csgo_parser\",\n",
    "    \"password\": \"3?6B7yTGPrkJF34p\",\n",
    "    \"host\": \"192.168.1.100\",\n",
    "    \"port\": \"5444\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96d0a003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Database connection established\n",
      "ðŸ“Š Helper functions defined successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Ensure we have a fresh connection\n",
    "try:\n",
    "    conn = psycopg2.connect(**DB_CONFIG)\n",
    "    print(\"âœ… Database connection established\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Connection error: {e}\")\n",
    "\n",
    "\n",
    "print(\"ðŸ“Š Helper functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "604138da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Fetching detailed round data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peter\\AppData\\Local\\Temp\\ipykernel_6092\\2205888952.py:150: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  detailed_df = pd.read_sql_query(query_detailed, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded 2,601,592 rounds with complete data\n",
      "\n",
      "ðŸ”¹ Pre-processing: Combining round end reasons 12 and 7\n",
      "   Round end reasons 12 merged into 7\n",
      "\n",
      "ðŸ”¹ Recoding round end reasons\n",
      "   Original distribution:\n",
      "      Reason 1: 407,446 rounds (15.66%)\n",
      "      Reason 7: 405,067 rounds (15.57%)\n",
      "      Reason 8: 934,538 rounds (35.92%)\n",
      "      Reason 9: 854,541 rounds (32.85%)\n",
      "   New distribution:\n",
      "      Reason 1: 407,446 rounds (15.66%)\n",
      "      Reason 2: 854,541 rounds (32.85%)\n",
      "      Reason 3: 405,067 rounds (15.57%)\n",
      "      Reason 4: 934,538 rounds (35.92%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query for detailed round outcomes\n",
    "query_detailed = \"\"\"\n",
    "WITH round_equipment AS (\n",
    "    SELECT \n",
    "        r.id,\n",
    "        r.match_id,\n",
    "        r.id_demo_exports,\n",
    "        r.round_num,\n",
    "        r.ct_winner,\n",
    "        r.team1_winner,\n",
    "        r.is_ct_t1,\n",
    "        r.round_end_reason,\n",
    "        -- CT team equipment\n",
    "        SUM(CASE WHEN (is_ct_t1 = (pr.team = 1)) THEN pr.eq_val_fte ELSE 0 END) as ct_equipment,\n",
    "        -- T team equipment\n",
    "        SUM(CASE WHEN (is_ct_t1 != (pr.team = 1)) THEN pr.eq_val_fte ELSE 0 END) as t_equipment,\n",
    "        hmi.team_1_id,\n",
    "        hmi.team_2_id,\n",
    "        hmi.event_id\n",
    "    FROM rounds_ed r\n",
    "    JOIN player_round_ed pr ON r.id = pr.round_id\n",
    "    LEFT JOIN hltv_match_info hmi ON r.match_id = hmi.match_id\n",
    "    WHERE pr.eq_val_fte > 0\n",
    "    GROUP BY 1,2,3,4,5,6,7,8, 11,12,13\n",
    "),\n",
    "bomb_planted AS (\n",
    "    SELECT \n",
    "        round_id,\n",
    "        CASE WHEN COUNT(*) > 0 THEN 1 ELSE 0 END as bomb_planted\n",
    "    FROM bomb_events_round_ed\n",
    "    WHERE bomb_event_type = 0\n",
    "    GROUP BY round_id\n",
    "),\n",
    "round_survivors AS (\n",
    "    SELECT \n",
    "        r.id as round_id,\n",
    "        r.is_ct_t1,\n",
    "        -- Count total players per team (5 players each)\n",
    "        -- CT survivors = 5 - (deaths of CT players)\n",
    "        5 - COUNT(DISTINCT CASE \n",
    "            WHEN (r.is_ct_t1 = (pv.team = 1)) THEN k.victim_hltv_id \n",
    "        END) as ct_survivors,\n",
    "        -- T survivors = 5 - (deaths of T players)\n",
    "        5 - COUNT(DISTINCT CASE \n",
    "            WHEN (r.is_ct_t1 != (pv.team = 1)) THEN k.victim_hltv_id \n",
    "        END) as t_survivors\n",
    "    FROM rounds_ed r\n",
    "    LEFT JOIN kills_round_ed k ON r.id = k.round_id\n",
    "    LEFT JOIN player_round_ed pv ON k.victim_hltv_id = pv.player_id AND k.round_id = pv.round_id and pv.player_id != 0\n",
    "    GROUP BY 1,2\n",
    "),\n",
    "saved_equipment AS (\n",
    "    SELECT \n",
    "        r.id as round_id,\n",
    "        r.is_ct_t1,\n",
    "        -- CT team saved equipment from player_economy_ed joined with player_round_ed\n",
    "        SUM(CASE WHEN (r.is_ct_t1 = (pr.team = 1)) THEN COALESCE(pe.saved_eq_val, 0) ELSE 0 END) as ct_saved_equipment,\n",
    "        -- T team saved equipment from player_economy_ed joined with player_round_ed\n",
    "        SUM(CASE WHEN (r.is_ct_t1 != (pr.team = 1)) THEN COALESCE(pe.saved_eq_val, 0) ELSE 0 END) as t_saved_equipment\n",
    "    FROM rounds_ed r\n",
    "    JOIN player_economy_ed pe ON r.id = pe.round_id\n",
    "    JOIN player_round_ed pr ON r.id = pr.round_id AND pe.player_id = pr.player_id and pr.player_id != 0\n",
    "    GROUP BY 1,2\n",
    "),\n",
    "player_money AS (\n",
    "    SELECT \n",
    "        r.id as round_id,\n",
    "        r.is_ct_t1,\n",
    "        -- CT team player money (money_earned + money_earned_re) joined with player_round_ed\n",
    "        SUM(CASE WHEN (r.is_ct_t1 = (pr.team = 1)) \n",
    "            THEN COALESCE(pe.money_earned, 0)\n",
    "            ELSE 0 END) as ct_player_money,\n",
    "        -- T team player money (money_earned + money_earned_re) joined with player_round_ed\n",
    "        SUM(CASE WHEN (r.is_ct_t1 != (pr.team = 1)) \n",
    "            THEN COALESCE(pe.money_earned, 0)  \n",
    "            ELSE 0 END) as t_player_money\n",
    "    FROM rounds_ed r\n",
    "    JOIN player_economy_ed pe ON r.id = pe.round_id\n",
    "    JOIN player_round_ed pr ON r.id = pr.round_id AND pe.player_id = pr.player_id and pr.player_id != 0\n",
    "    GROUP BY 1,2\n",
    "), \n",
    "ranked_data AS (\n",
    "    SELECT \n",
    "        trd.id,\n",
    "        trd.id_demo_exports,\n",
    "        trd.round_num,\n",
    "        trd.team1_winner,\n",
    "        -- Team 1 metrics\n",
    "        CAST(het1.rank_during AS INTEGER) as t1_rank,\n",
    "        -- Team 2 metrics\n",
    "        CAST(het2.rank_during AS INTEGER) as t2_rank\n",
    "    FROM round_equipment trd\n",
    "    LEFT JOIN hltv_events_teams het1 ON het1.team_id = trd.team_1_id AND het1.event_id = trd.event_id\n",
    "    LEFT JOIN hltv_events_teams het2 ON het2.team_id = trd.team_2_id AND het2.event_id = trd.event_id\n",
    "    WHERE het1.rank_during IS NOT NULL \n",
    "        AND het2.rank_during IS NOT NULL\n",
    ")\n",
    "SELECT \n",
    "    re.*,\n",
    "    -- Add bomb planted status\n",
    "    COALESCE(bp.bomb_planted, 0) as bomb_planted,\n",
    "    -- Add survivor counts from round_survivors CTE\n",
    "    rs.ct_survivors,\n",
    "    rs.t_survivors,\n",
    "    -- Higher and lower equipment\n",
    "    CASE \n",
    "        WHEN re.ct_equipment > re.t_equipment THEN re.ct_equipment\n",
    "        ELSE re.t_equipment\n",
    "    END as higher_equipment,\n",
    "    CASE \n",
    "        WHEN re.ct_equipment <= re.t_equipment THEN re.ct_equipment\n",
    "        ELSE re.t_equipment\n",
    "    END as lower_equipment,\n",
    "    -- Did higher equipment team win?\n",
    "    CASE \n",
    "        WHEN (re.ct_equipment > re.t_equipment AND re.ct_winner)\n",
    "        OR (re.ct_equipment < re.t_equipment AND NOT re.ct_winner)\n",
    "        THEN 1\n",
    "        ELSE 0\n",
    "    END as higher_eq_won,\n",
    "    -- Winner's survivors (only from is_alive_re)\n",
    "    CASE \n",
    "        WHEN re.ct_winner THEN rs.ct_survivors\n",
    "        ELSE rs.t_survivors\n",
    "    END as winner_survivors,\n",
    "    -- Winner's saved equipment (from player_economy_ed.saved_eq_val)\n",
    "    CASE \n",
    "        WHEN re.ct_winner THEN se.ct_saved_equipment\n",
    "        ELSE se.t_saved_equipment\n",
    "    END as winner_saved_equipment,\n",
    "    -- CT and T saved equipment \n",
    "    se.ct_saved_equipment,\n",
    "    se.t_saved_equipment,\n",
    "    -- All money columns for analysis\n",
    "    pm.ct_player_money,\n",
    "    pm.t_player_money,\n",
    "    rd.t1_rank,\n",
    "    rd.t2_rank\n",
    "FROM round_equipment re\n",
    "LEFT JOIN bomb_planted bp ON re.id = bp.round_id\n",
    "LEFT JOIN round_survivors rs ON re.id = rs.round_id\n",
    "LEFT JOIN saved_equipment se ON re.id = se.round_id\n",
    "LEFT JOIN player_money pm ON re.id = pm.round_id\n",
    "LEFT JOIN ranked_data rd ON re.id = rd.id\n",
    "WHERE re.ct_equipment > 0 AND re.t_equipment > 0 \n",
    "ORDER BY re.match_id, re.round_num\n",
    "\"\"\"\n",
    "\n",
    "print(\"ðŸ“Š Fetching detailed round data...\")\n",
    "detailed_df = pd.read_sql_query(query_detailed, conn)\n",
    "print(f\"âœ… Loaded {len(detailed_df):,} rounds with complete data\")\n",
    "print()\n",
    "\n",
    "# Combine round end reasons 12 and 7\n",
    "print(\"ðŸ”¹ Pre-processing: Combining round end reasons 12 and 7\")\n",
    "detailed_df['round_end_reason'] = detailed_df['round_end_reason'].replace({12: 7})\n",
    "print(f\"   Round end reasons 12 merged into 7\")\n",
    "print()\n",
    "\n",
    "# Recode round end reasons: 1â†’1, 9â†’2, 7â†’3, 8â†’4\n",
    "print(\"ðŸ”¹ Recoding round end reasons\")\n",
    "original_count = len(detailed_df)\n",
    "print(f\"   Original distribution:\")\n",
    "for old_code in [1, 7, 8, 9]:\n",
    "    count = (detailed_df['round_end_reason'] == old_code).sum()\n",
    "    pct = count / len(detailed_df) * 100 if len(detailed_df) > 0 else 0\n",
    "    print(f\"      Reason {old_code}: {count:,} rounds ({pct:.2f}%)\")\n",
    "\n",
    "detailed_df['round_end_reason'] = detailed_df['round_end_reason'].replace({\n",
    "    1: 1,  # T Win (Target Bombed) - no change\n",
    "    9: 2,  # T Win (Elimination) - 9 â†’ 2\n",
    "    7: 3,  # CT Win (Defuse) - 7 â†’ 3\n",
    "    8: 4,  # CT Win (Elimination) - 8 â†’ 4\n",
    "})\n",
    "\n",
    "print(f\"   New distribution:\")\n",
    "for new_code in [1, 2, 3, 4]:\n",
    "    count = (detailed_df['round_end_reason'] == new_code).sum()\n",
    "    pct = count / len(detailed_df) * 100 if len(detailed_df) > 0 else 0\n",
    "    print(f\"      Reason {new_code}: {count:,} rounds ({pct:.2f}%)\")\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bddc4007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Filtering inconsistent Reason 2 (T Win Elimination) rounds:\n",
      "   Found 2,821 rounds where Reason 2 occurred but CT had survivors > 0\n",
      "   Removed: 2,821 rounds\n",
      "   Remaining: 2,598,771 rounds\n",
      "\n",
      "âœ… Data quality filtering complete\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Filter out inconsistent data\n",
    "# Reason 2 (T Win Elimination - was 9) should have CT survivors = 0\n",
    "filtered_9 = (detailed_df['round_end_reason'] == 2) & (detailed_df['ct_survivors'] > 0)\n",
    "reason_9_issues = detailed_df[filtered_9]\n",
    "print(f\"ðŸ”¹ Filtering inconsistent Reason 2 (T Win Elimination) rounds:\")\n",
    "print(f\"   Found {len(reason_9_issues):,} rounds where Reason 2 occurred but CT had survivors > 0\")\n",
    "\n",
    "before = len(detailed_df)\n",
    "detailed_df = detailed_df[~filtered_9]\n",
    "total_filtered = before - len(detailed_df)\n",
    "\n",
    "print(f\"   Removed: {total_filtered:,} rounds\")\n",
    "print(f\"   Remaining: {len(detailed_df):,} rounds\")\n",
    "print()\n",
    "print(\"âœ… Data quality filtering complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc841625",
   "metadata": {},
   "source": [
    "# The Data Science/ Data Engineering part\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5ab81b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import *\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "test_size_global = 0.3\n",
    "random_state_global = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85a033a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.582403\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              ct_winner   No. Observations:              1819139\n",
      "Model:                          Logit   Df Residuals:                  1819137\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Tue, 20 Jan 2026   Pseudo R-squ.:                  0.1592\n",
      "Time:                        17:57:28   Log-Likelihood:            -1.0595e+06\n",
      "converged:                       True   LL-Null:                   -1.2601e+06\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.0021      0.002     -1.255      0.210      -0.005       0.001\n",
      "ct_t_ratio     1.0834      0.002    480.202      0.000       1.079       1.088\n",
      "==============================================================================\n",
      "Confusion Matrix : \n",
      " [[206322 171592]\n",
      " [ 95979 305739]]\n",
      "Test accuracy =  0.6567983356250128\n",
      "Test AUC-ROC =  0.7381975896382249\n"
     ]
    }
   ],
   "source": [
    "detailed_df['ct_t_ratio'] = np.log(detailed_df['ct_equipment'] / detailed_df['t_equipment'])\n",
    "x_r = detailed_df[['ct_t_ratio']]\n",
    "y = detailed_df['ct_winner']\n",
    "\n",
    "# Split data\n",
    "xtr_train, xtr_test, ytr_train, ytr_test = train_test_split(x_r, y, test_size=test_size_global, random_state=random_state_global)\n",
    "# train dataset\n",
    "log_model = sm.Logit(ytr_train, sm.add_constant(xtr_train))\n",
    "result = log_model.fit()\n",
    "print(result.summary())\n",
    "\n",
    "# test dataset\n",
    "yhat = result.predict(sm.add_constant(xtr_test))\n",
    "prediction = list(map(round, yhat))\n",
    "\n",
    "cm = confusion_matrix(ytr_test, prediction) \n",
    "auc_score = roc_auc_score(ytr_test, yhat)\n",
    "fpr, tpr, _ = roc_curve(ytr_test, yhat)\n",
    "\n",
    "print (\"Confusion Matrix : \\n\", cm) \n",
    "print('Test accuracy = ', accuracy_score(ytr_test, prediction))\n",
    "print('Test AUC-ROC = ', auc_score) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "077510d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.582394\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              ct_winner   No. Observations:              1819139\n",
      "Model:                          Logit   Df Residuals:                  1819136\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Tue, 20 Jan 2026   Pseudo R-squ.:                  0.1592\n",
      "Time:                        17:57:38   Log-Likelihood:            -1.0595e+06\n",
      "converged:                       True   LL-Null:                   -1.2601e+06\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "================================================================================\n",
      "                   coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "const           -0.1592      0.028     -5.750      0.000      -0.214      -0.105\n",
      "ct_equipment     1.0902      0.003    426.197      0.000       1.085       1.095\n",
      "t_equipment     -1.0742      0.003   -387.795      0.000      -1.080      -1.069\n",
      "================================================================================\n",
      "Confusion Matrix : \n",
      " [[209099 168815]\n",
      " [ 98883 302835]]\n",
      "Test accuracy =  0.6566354382580499\n",
      "Test AUC-ROC =  0.7381937127383316\n"
     ]
    }
   ],
   "source": [
    "x = np.log(detailed_df[['ct_equipment', 't_equipment']])\n",
    "y = detailed_df['ct_winner']\n",
    "\n",
    "# Split data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size_global, random_state=random_state_global)\n",
    "\n",
    "# train dataset\n",
    "log2_model = sm.Logit(y_train, sm.add_constant(x_train))\n",
    "result2 = log2_model.fit()\n",
    "print(result2.summary())\n",
    "\n",
    "# test dataset\n",
    "yhat2 = result2.predict(sm.add_constant(x_test))\n",
    "prediction = list(map(round, yhat2))\n",
    "\n",
    "cm = confusion_matrix(y_test, prediction) \n",
    "auc_score = roc_auc_score(ytr_test, yhat2)\n",
    "fpr, tpr, _ = roc_curve(ytr_test, yhat2)\n",
    "\n",
    "print (\"Confusion Matrix : \\n\", cm) \n",
    "print('Test accuracy = ', accuracy_score(ytr_test, prediction))\n",
    "print('Test AUC-ROC = ', auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59c010e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.582606\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              ct_winner   No. Observations:              1274806\n",
      "Model:                          Logit   Df Residuals:                  1274803\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Tue, 20 Jan 2026   Pseudo R-squ.:                  0.1588\n",
      "Time:                        17:58:49   Log-Likelihood:            -7.4271e+05\n",
      "converged:                       True   LL-Null:                   -8.8295e+05\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.0047      0.002     -2.354      0.019      -0.009      -0.001\n",
      "ct_t_ratio     1.0842      0.003    396.159      0.000       1.079       1.090\n",
      "rank_diff     -0.0021   3.51e-05    -59.826      0.000      -0.002      -0.002\n",
      "==============================================================================\n",
      "Confusion Matrix : \n",
      " [[149271 115039]\n",
      " [ 71381 210655]]\n",
      "Test accuracy =  0.6587876547096528\n",
      "Test AUC-ROC =  0.7393234846097624\n",
      "\n",
      "==================================================\n",
      "Wald Test for rank_diff\n",
      "==================================================\n",
      "Coefficient: -0.002099\n",
      "Standard Error: 0.000035\n",
      "Wald Statistic: 3579.1510\n",
      "P-value: 0.000000\n",
      "Significance: ***\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats as scipy_stats\n",
    "\n",
    "# Add difference in rank to the regression\n",
    "detailed_df = detailed_df.dropna(subset=['t1_rank', 't2_rank'])\n",
    "detailed_df['ct_rank'] = detailed_df.apply(lambda row: row['t1_rank'] if row['is_ct_t1'] else row['t2_rank'], axis=1)\n",
    "detailed_df['t_rank'] = detailed_df.apply(lambda row: row['t2_rank'] if row['is_ct_t1'] else row['t1_rank'], axis=1)\n",
    "detailed_df['rank_diff'] = detailed_df['ct_rank'] - detailed_df['t_rank']\n",
    "detailed_df['ct_t_ratio'] = np.log(detailed_df['ct_equipment'] / detailed_df['t_equipment'])\n",
    "\n",
    "# Filter out rows with missing rank_diff values\n",
    "df_with_ranks = detailed_df[['ct_t_ratio', 'rank_diff', 'ct_winner']].dropna()\n",
    "X = df_with_ranks[['ct_t_ratio', 'rank_diff']].copy()\n",
    "y = df_with_ranks['ct_winner']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size_global, random_state=random_state_global)\n",
    "\n",
    "# Fit logistic regression with statsmodels\n",
    "logit_model = sm.Logit(y_train, sm.add_constant(X_train))\n",
    "result = logit_model.fit()\n",
    "print(result.summary())\n",
    "\n",
    "# Predict and evaluate\n",
    "yhat = result.predict(sm.add_constant(X_test))\n",
    "prediction = list(map(round, yhat))\n",
    "\n",
    "cm = confusion_matrix(y_test, prediction)\n",
    "auc_score = roc_auc_score(y_test, yhat)\n",
    "fpr, tpr, _ = roc_curve(y_test, yhat)\n",
    "\n",
    "print(\"Confusion Matrix : \\n\", cm)\n",
    "print('Test accuracy = ', accuracy_score(y_test, prediction))\n",
    "print('Test AUC-ROC = ', auc_score)\n",
    "\n",
    "# Perform Wald test for rank_diff coefficient\n",
    "\n",
    "# Get the coefficient and standard error for rank_diff\n",
    "rank_diff_coef = result.params['rank_diff']\n",
    "rank_diff_se = result.bse['rank_diff']\n",
    "\n",
    "# Calculate Wald statistic: (coefficient / std_error)^2\n",
    "wald_stat = (rank_diff_coef / rank_diff_se) ** 2\n",
    "\n",
    "# Calculate p-value (chi-square distribution with 1 degree of freedom)\n",
    "p_value = 1 - scipy_stats.chi2.cdf(wald_stat, df=1)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Wald Test for rank_diff\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Coefficient: {rank_diff_coef:.6f}\")\n",
    "print(f\"Standard Error: {rank_diff_se:.6f}\")\n",
    "print(f\"Wald Statistic: {wald_stat:.4f}\")\n",
    "print(f\"P-value: {p_value:.6f}\")\n",
    "print(f\"Significance: {'***' if p_value < 0.001 else '**' if p_value < 0.01 else '*' if p_value < 0.05 else 'Not significant'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08822a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.582566\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              ct_winner   No. Observations:              1274806\n",
      "Model:                          Logit   Df Residuals:                  1274801\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Tue, 20 Jan 2026   Pseudo R-squ.:                  0.1589\n",
      "Time:                        17:58:56   Log-Likelihood:            -7.4266e+05\n",
      "converged:                       True   LL-Null:                   -8.8295e+05\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "================================================================================\n",
      "                   coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "const           -0.1578      0.034     -4.576      0.000      -0.225      -0.090\n",
      "ct_equipment     1.0908      0.003    352.157      0.000       1.085       1.097\n",
      "t_equipment     -1.0752      0.003   -321.253      0.000      -1.082      -1.069\n",
      "ct_rank         -0.1383      0.003    -54.303      0.000      -0.143      -0.133\n",
      "t_rank           0.1382      0.003     54.435      0.000       0.133       0.143\n",
      "================================================================================\n",
      "Confusion Matrix : \n",
      " [[149974 114336]\n",
      " [ 72232 209804]]\n",
      "Test accuracy =  0.6585167641018695\n",
      "Test AUC-ROC =  0.7393693033832669\n"
     ]
    }
   ],
   "source": [
    "x = np.log(detailed_df[['ct_equipment', 't_equipment', 'ct_rank', 't_rank']])\n",
    "y = detailed_df['ct_winner']\n",
    "\n",
    "# Split data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size_global, random_state=random_state_global)\n",
    "\n",
    "# train dataset\n",
    "log2_model = sm.Logit(y_train, sm.add_constant(x_train))\n",
    "result2 = log2_model.fit()\n",
    "print(result2.summary())\n",
    "\n",
    "# test dataset\n",
    "yhat2 = result2.predict(sm.add_constant(x_test))\n",
    "prediction = list(map(round, yhat2))\n",
    "\n",
    "cm = confusion_matrix(y_test, prediction) \n",
    "auc_score = roc_auc_score(y_test, yhat2)\n",
    "fpr, tpr, _ = roc_curve(y_test, yhat2)\n",
    "\n",
    "print (\"Confusion Matrix : \\n\", cm) \n",
    "print('Test accuracy = ', accuracy_score(y_test, prediction))\n",
    "print('Test AUC-ROC = ', auc_score) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a7237c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.582574\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              ct_winner   No. Observations:              1274806\n",
      "Model:                          Logit   Df Residuals:                  1274803\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Tue, 20 Jan 2026   Pseudo R-squ.:                  0.1589\n",
      "Time:                        17:59:03   Log-Likelihood:            -7.4267e+05\n",
      "converged:                       True   LL-Null:                   -8.8295e+05\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "=================================================================================\n",
      "                    coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "const            -0.0045      0.002     -2.290      0.022      -0.008      -0.001\n",
      "rank_log_diff    -0.1382      0.002    -60.538      0.000      -0.143      -0.134\n",
      "eq_log_diff       1.0841      0.003    396.113      0.000       1.079       1.089\n",
      "=================================================================================\n",
      "Confusion Matrix : \n",
      " [[149700 114610]\n",
      " [ 72058 209978]]\n",
      "Test accuracy =  0.6583337299074213\n",
      "Test AUC-ROC =  0.7393804551201115\n",
      "\n",
      "==================================================\n",
      "Model Coefficients and P-values\n",
      "==================================================\n",
      "\n",
      "rank_log_diff:\n",
      "  Coefficient: -0.138234\n",
      "  Std Error: 0.002283\n",
      "  P-value: 0.000000\n",
      "  Significance: ***\n",
      "\n",
      "eq_log_diff:\n",
      "  Coefficient: 1.084124\n",
      "  Std Error: 0.002737\n",
      "  P-value: 0.000000\n",
      "  Significance: ***\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats as scipy_stats\n",
    "\n",
    "# Add difference in rank to the regression\n",
    "detailed_df = detailed_df.dropna(subset=['t1_rank', 't2_rank'])\n",
    "detailed_df['rank_log_diff'] = np.log(detailed_df['ct_rank']) - np.log(detailed_df['t_rank'])\n",
    "detailed_df['eq_log_diff'] = np.log(detailed_df['ct_equipment']) - np.log(detailed_df['t_equipment'])\n",
    "\n",
    "# Filter out rows with missing rank_diff values\n",
    "df_with_ranks = detailed_df[['rank_log_diff', 'eq_log_diff', 'ct_winner']].dropna()\n",
    "X = df_with_ranks[['rank_log_diff', 'eq_log_diff']].copy()\n",
    "y = df_with_ranks['ct_winner']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size_global, random_state=random_state_global)\n",
    "\n",
    "# Fit logistic regression with statsmodels\n",
    "logit_model = sm.Logit(y_train, sm.add_constant(X_train))\n",
    "result = logit_model.fit()\n",
    "print(result.summary())\n",
    "\n",
    "# Predict and evaluate\n",
    "yhat = result.predict(sm.add_constant(X_test))\n",
    "prediction = list(map(round, yhat))\n",
    "\n",
    "cm = confusion_matrix(y_test, prediction)\n",
    "auc_score = roc_auc_score(y_test, yhat)\n",
    "fpr, tpr, _ = roc_curve(y_test, yhat)\n",
    "\n",
    "print(\"Confusion Matrix : \\n\", cm)\n",
    "print('Test accuracy = ', accuracy_score(y_test, prediction))\n",
    "print('Test AUC-ROC = ', auc_score)\n",
    "\n",
    "# Extract coefficients and p-values\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Model Coefficients and P-values\")\n",
    "print(\"=\"*50)\n",
    "for var in ['rank_log_diff', 'eq_log_diff']:\n",
    "    coef = result.params[var]\n",
    "    pval = result.pvalues[var]\n",
    "    se = result.bse[var]\n",
    "    print(f\"\\n{var}:\")\n",
    "    print(f\"  Coefficient: {coef:.6f}\")\n",
    "    print(f\"  Std Error: {se:.6f}\")\n",
    "    print(f\"  P-value: {pval:.6f}\")\n",
    "    print(f\"  Significance: {'***' if pval < 0.001 else '**' if pval < 0.01 else '*' if pval < 0.05 else 'Not significant'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed938bec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
