{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf6e1f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries - Enhanced for Statistical Analysis\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "# Set Up Database Connection\n",
    "# Replace the placeholders with your actual database credentials\n",
    "DB_CONFIG = {\n",
    "    \"dbname\": \"csgo_parsed\",\n",
    "    \"user\": \"csgo_parser\",\n",
    "    \"password\": \"3?6B7yTGPrkJF34p\",\n",
    "    \"host\": \"192.168.1.100\",\n",
    "    \"port\": \"5444\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96d0a003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Database connection established\n",
      "üìä Helper functions defined successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Ensure we have a fresh connection\n",
    "try:\n",
    "    conn = psycopg2.connect(**DB_CONFIG)\n",
    "    print(\"‚úÖ Database connection established\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Connection error: {e}\")\n",
    "\n",
    "def get_descriptive_stats(data, column_name):\n",
    "    \"\"\"Calculate comprehensive descriptive statistics\"\"\"\n",
    "    stats_dict = {\n",
    "        'count': len(data),\n",
    "        'min': data.min(),\n",
    "        'max': data.max(),\n",
    "        'mean': data.mean(),\n",
    "        'median': data.median(),\n",
    "        'std': data.std(),\n",
    "        'q25': data.quantile(0.25),\n",
    "        'q75': data.quantile(0.75)\n",
    "    }\n",
    "    return stats_dict\n",
    "\n",
    "def get_top_values(data, n=15):\n",
    "    \"\"\"Get top N occurring values with percentages\"\"\"\n",
    "    value_counts = data.value_counts().head(n)\n",
    "    percentages = (value_counts / len(data) * 100).round(2)\n",
    "    return pd.DataFrame({\n",
    "        'value': value_counts.index,\n",
    "        'count': value_counts.values,\n",
    "        'percentage': percentages.values\n",
    "    })\n",
    "\n",
    "def create_distribution_plots(data, title, bins=50):\n",
    "    \"\"\"Create histogram and box plot for a variable\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Histogram\n",
    "    ax1.hist(data.dropna(), bins=bins, alpha=0.7, edgecolor='black')\n",
    "    ax1.set_title(f'{title} - Distribution')\n",
    "    ax1.set_xlabel('Value')\n",
    "    ax1.set_ylabel('Frequency')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Box plot\n",
    "    ax2.boxplot(data.dropna())\n",
    "    ax2.set_title(f'{title} - Box Plot')\n",
    "    ax2.set_ylabel('Value')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"üìä Helper functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3437ca30",
   "metadata": {},
   "source": [
    "# CS:GO Economy Agent-Based Model (ABM) - Data Analysis\n",
    "## Objective: Extract real-game statistics to parameterize an ABM for CS:GO economy decisions\n",
    "\n",
    "This notebook analyzes real CS:GO match data to determine key distributions and probabilities for:\n",
    "1. **Win probability** based on team equipment value/spending and other factors\n",
    "2. **Remaining players** after round outcomes\n",
    "3. **Saved equipment** based on round results\n",
    "4. **Additional probabilities** for round end conditions (bomb events, eliminations, etc.)\n",
    "\n",
    "The goal is to create realistic probability distributions for an ABM that simulates CS:GO buy-time decisions and their outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f3511c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Querying team equipment and outcome data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peter\\AppData\\Local\\Temp\\ipykernel_28844\\363057051.py:61: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  team_data = pd.read_sql(team_equipment_query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Retrieved 2,601,262 team rounds from 98,925 matches\n",
      "\n",
      "üîç Team equipment data preview:\n",
      "   round_id  id_demo_exports  round_num  t1_avg_eq_val_fte  t1_total_spent  \\\n",
      "0      5891              184          1              830.0          3550.0   \n",
      "1      5892              184          2             1940.0         10000.0   \n",
      "2      5893              184          3              600.0          2800.0   \n",
      "3      5894              184          4             4920.0         23600.0   \n",
      "4      5895              184          5             4250.0         16150.0   \n",
      "\n",
      "   t1_survivors  t1_saved_eq  t2_avg_eq_val_fte  t2_total_spent  t2_survivors  \\\n",
      "0             1          950              800.0          3400.0             4   \n",
      "1             1         2050             4320.0         17400.0             3   \n",
      "2             1          700             4380.0          9350.0             5   \n",
      "3             1         4300             5370.0          6500.0             1   \n",
      "4             2         8400             5630.0         27550.0             2   \n",
      "\n",
      "   t2_saved_eq  team1_winner  ct_winner  eq_advantage_t1  \\\n",
      "0         3600         False       True             30.0   \n",
      "1        14600         False       True          -2380.0   \n",
      "2        23850         False       True          -3780.0   \n",
      "3         5350          True      False           -450.0   \n",
      "4         9650          True      False          -1380.0   \n",
      "\n",
      "   spending_advantage_t1  \n",
      "0                  150.0  \n",
      "1                -7400.0  \n",
      "2                -6550.0  \n",
      "3                17100.0  \n",
      "4               -11400.0  \n",
      "\n",
      "Data shape: (2601262, 15)\n",
      "Columns: ['round_id', 'id_demo_exports', 'round_num', 't1_avg_eq_val_fte', 't1_total_spent', 't1_survivors', 't1_saved_eq', 't2_avg_eq_val_fte', 't2_total_spent', 't2_survivors', 't2_saved_eq', 'team1_winner', 'ct_winner', 'eq_advantage_t1', 'spending_advantage_t1']\n"
     ]
    }
   ],
   "source": [
    "# 1. Team Equipment Value vs Win Probability Analysis\n",
    "# Query team-level equipment and round outcomes\n",
    "\n",
    "team_equipment_query = \"\"\"\n",
    "WITH team_round_data AS (\n",
    "    SELECT \n",
    "        r.id as round_id,\n",
    "        r.id_demo_exports,\n",
    "        r.round_num,\n",
    "        r.team1_winner,\n",
    "        r.ct_winner,\n",
    "        -- Team 1 data\n",
    "        AVG(CASE WHEN pr.team = 1 THEN pr.eq_val_fte END) as t1_avg_eq_val_fte,\n",
    "        SUM(CASE WHEN pr.team = 1 THEN pe.money_spent END) as t1_total_spent,\n",
    "        COUNT(CASE WHEN pr.team = 1 THEN 1 END) as t1_players,\n",
    "        -- Team 2 data  \n",
    "        AVG(CASE WHEN pr.team = 2 THEN pr.eq_val_fte END) as t2_avg_eq_val_fte,\n",
    "        SUM(CASE WHEN pr.team = 2 THEN pe.money_spent END) as t2_total_spent,\n",
    "        COUNT(CASE WHEN pr.team = 2 THEN 1 END) as t2_players,\n",
    "        -- Round end analysis\n",
    "        COUNT(CASE WHEN pr.team = 1 AND pr.is_alive_re = true THEN 1 END) as t1_survivors,\n",
    "        COUNT(CASE WHEN pr.team = 2 AND pr.is_alive_re = true THEN 1 END) as t2_survivors,\n",
    "        -- Equipment saved (equipment value of survivors)\n",
    "        SUM(CASE WHEN pr.team = 1 AND pr.is_alive_re = true THEN pr.eq_val_re END) as t1_saved_eq,\n",
    "        SUM(CASE WHEN pr.team = 2 AND pr.is_alive_re = true THEN pr.eq_val_re END) as t2_saved_eq\n",
    "    FROM rounds_ed r\n",
    "    JOIN player_round_ed pr ON r.id = pr.round_id\n",
    "    LEFT JOIN player_economy_ed pe ON pr.id = pe.player_round_id\n",
    "    WHERE r.team1_winner IS NOT NULL\n",
    "        AND pr.team IN (1, 2)\n",
    "        AND pr.eq_val_fte IS NOT NULL\n",
    "    GROUP BY r.id, r.id_demo_exports, r.round_num, r.team1_winner, r.ct_winner\n",
    "    HAVING COUNT(CASE WHEN pr.team = 1 THEN 1 END) = 5 \n",
    "       AND COUNT(CASE WHEN pr.team = 2 THEN 1 END) = 5  -- Ensure full teams\n",
    ")\n",
    "SELECT \n",
    "    round_id,\n",
    "    id_demo_exports,\n",
    "    round_num,\n",
    "    -- Team 1 metrics\n",
    "    t1_avg_eq_val_fte,\n",
    "    t1_total_spent,\n",
    "    t1_survivors,\n",
    "    COALESCE(t1_saved_eq, 0) as t1_saved_eq,\n",
    "    -- Team 2 metrics\n",
    "    t2_avg_eq_val_fte, \n",
    "    t2_total_spent,\n",
    "    t2_survivors,\n",
    "    COALESCE(t2_saved_eq, 0) as t2_saved_eq,\n",
    "    -- Outcomes\n",
    "    team1_winner,\n",
    "    ct_winner,\n",
    "    -- Equipment advantage\n",
    "    (t1_avg_eq_val_fte - t2_avg_eq_val_fte) as eq_advantage_t1,\n",
    "    (t1_total_spent - t2_total_spent) as spending_advantage_t1\n",
    "FROM team_round_data\n",
    "WHERE t1_avg_eq_val_fte IS NOT NULL AND t2_avg_eq_val_fte IS NOT NULL\n",
    "\"\"\"\n",
    "\n",
    "print(\"üîç Querying team equipment and outcome data...\")\n",
    "team_data = pd.read_sql(team_equipment_query, conn)\n",
    "print(f\"üìä Retrieved {len(team_data):,} team rounds from {team_data['id_demo_exports'].nunique():,} matches\")\n",
    "\n",
    "# Preview the data\n",
    "print(\"\\nüîç Team equipment data preview:\")\n",
    "print(team_data.head())\n",
    "print(f\"\\nData shape: {team_data.shape}\")\n",
    "print(f\"Columns: {list(team_data.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c86bb08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ TEAM 1 WIN PROBABILITY BY EQUIPMENT VALUE\n",
      "============================================================\n",
      "             Total_Rounds    Wins  Win_Rate  Avg_Equipment  Avg_Survivors  \\\n",
      "t1_eq_range                                                                 \n",
      "$0-1k              410679  117278     0.286        648.806          1.459   \n",
      "$1-2k              168348   36657     0.218       1497.286          1.356   \n",
      "$2-3k              105927   35369     0.334       2445.067          1.599   \n",
      "$3-4k              192263  113657     0.591       3623.801          2.213   \n",
      "$4-5k              525440  301721     0.574       4579.913          2.135   \n",
      "$5-6k              850484  506188     0.595       5456.757          2.186   \n",
      "$6k+               348121  229309     0.659       6342.237          2.481   \n",
      "\n",
      "             Avg_Saved_Eq  \n",
      "t1_eq_range                \n",
      "$0-1k            1633.140  \n",
      "$1-2k            3737.556  \n",
      "$2-3k            5748.082  \n",
      "$3-4k            9160.849  \n",
      "$4-5k           10164.803  \n",
      "$5-6k           11921.359  \n",
      "$6k+            15518.322  \n",
      "\n",
      "üí∞ WIN PROBABILITY BY EQUIPMENT ADVANTAGE\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peter\\AppData\\Local\\Temp\\ipykernel_28844\\3862538629.py:13: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  t1_win_by_eq = team_data.groupby('t1_eq_range').agg({\n",
      "C:\\Users\\peter\\AppData\\Local\\Temp\\ipykernel_28844\\3862538629.py:33: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  eq_advantage_analysis = team_data.groupby('eq_advantage_bins').agg({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Count  T1_Win_Rate  Avg_Eq_Advantage  T1_Avg_Survivors  \\\n",
      "eq_advantage_bins                                                             \n",
      "T1 Very Behind      509660        0.190         -3784.589             1.282   \n",
      "T1 Behind           272435        0.419         -1443.889             1.650   \n",
      "T1 Slightly Behind  192038        0.472          -741.666             1.772   \n",
      "Balanced            595529        0.511             2.956             1.898   \n",
      "T1 Slightly Ahead   195267        0.551           753.515             2.077   \n",
      "T1 Ahead            286975        0.607          1454.945             2.215   \n",
      "T1 Very Ahead       549358        0.823          3803.691             3.008   \n",
      "\n",
      "                    T2_Avg_Survivors  \n",
      "eq_advantage_bins                     \n",
      "T1 Very Behind                 2.955  \n",
      "T1 Behind                      2.153  \n",
      "T1 Slightly Behind             2.025  \n",
      "Balanced                       1.849  \n",
      "T1 Slightly Ahead              1.724  \n",
      "T1 Ahead                       1.596  \n",
      "T1 Very Ahead                  1.258  \n",
      "\n",
      "üìà Statistical significance of equipment advantage:\n",
      "High advantage win rate: 0.749\n",
      "Low advantage win rate: 0.269\n",
      "T-test p-value: nan\n"
     ]
    }
   ],
   "source": [
    "# 1.1 Win Probability Analysis by Equipment Value\n",
    "\n",
    "# Calculate win probabilities by continuous equipment values\n",
    "print(\"üéØ TEAM 1 WIN PROBABILITY BY EQUIPMENT VALUE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Team 1 win probability by equipment value ranges  \n",
    "eq_bins = [0, 1000, 2000, 3000, 4000, 5000, 6000, np.inf]\n",
    "eq_labels = ['$0-1k', '$1-2k', '$2-3k', '$3-4k', '$4-5k', '$5-6k', '$6k+']\n",
    "\n",
    "team_data['t1_eq_range'] = pd.cut(team_data['t1_avg_eq_val_fte'], bins=eq_bins, labels=eq_labels)\n",
    "\n",
    "t1_win_by_eq = team_data.groupby('t1_eq_range').agg({\n",
    "    'team1_winner': ['count', 'sum', 'mean'],\n",
    "    't1_avg_eq_val_fte': 'mean',\n",
    "    't1_survivors': 'mean',\n",
    "    't1_saved_eq': 'mean'\n",
    "}).round(3)\n",
    "\n",
    "t1_win_by_eq.columns = ['Total_Rounds', 'Wins', 'Win_Rate', 'Avg_Equipment', 'Avg_Survivors', 'Avg_Saved_Eq']\n",
    "print(t1_win_by_eq)\n",
    "\n",
    "# Equipment advantage analysis\n",
    "print(f\"\\nüí∞ WIN PROBABILITY BY EQUIPMENT ADVANTAGE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create equipment advantage bins\n",
    "team_data['eq_advantage_bins'] = pd.cut(team_data['eq_advantage_t1'], \n",
    "                                       bins=[-np.inf, -2000, -1000, -500, 500, 1000, 2000, np.inf],\n",
    "                                       labels=['T1 Very Behind', 'T1 Behind', 'T1 Slightly Behind', \n",
    "                                              'Balanced', 'T1 Slightly Ahead', 'T1 Ahead', 'T1 Very Ahead'])\n",
    "\n",
    "eq_advantage_analysis = team_data.groupby('eq_advantage_bins').agg({\n",
    "    'team1_winner': ['count', 'mean'],\n",
    "    'eq_advantage_t1': 'mean',\n",
    "    't1_survivors': 'mean',\n",
    "    't2_survivors': 'mean'\n",
    "}).round(3)\n",
    "\n",
    "eq_advantage_analysis.columns = ['Count', 'T1_Win_Rate', 'Avg_Eq_Advantage', 'T1_Avg_Survivors', 'T2_Avg_Survivors']\n",
    "print(eq_advantage_analysis)\n",
    "\n",
    "# Statistical significance of equipment advantage\n",
    "from scipy import stats\n",
    "high_eq_adv = team_data[team_data['eq_advantage_t1'] > 1000]['team1_winner']\n",
    "low_eq_adv = team_data[team_data['eq_advantage_t1'] < -1000]['team1_winner']\n",
    "stat, p_value = stats.ttest_ind(high_eq_adv, low_eq_adv)\n",
    "print(f\"\\nüìà Statistical significance of equipment advantage:\")\n",
    "print(f\"High advantage win rate: {high_eq_adv.mean():.3f}\")\n",
    "print(f\"Low advantage win rate: {low_eq_adv.mean():.3f}\")\n",
    "print(f\"T-test p-value: {p_value:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf7c3411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÜ EXPLORING TEAM RANKING DATA\n",
      "==================================================\n",
      "üîç Querying team ranking information...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peter\\AppData\\Local\\Temp\\ipykernel_28844\\1891595877.py:33: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  team_ranking_data = pd.read_sql(team_info_query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Found 1,000 rounds with team ranking data\n",
      "\n",
      "üîç Team ranking data preview:\n",
      "   id_demo_exports  match_id  event_id  team_1_id  team_2_id team_1_name  \\\n",
      "0                1   2367066      7454      12318      11814     Intense   \n",
      "1                1   2367066      7454      12318      11814     Intense   \n",
      "2                2   2367066      7454      12318      11814     Intense   \n",
      "3                2   2367066      7454      12318      11814     Intense   \n",
      "4                3   2367066      7454      12318      11814     Intense   \n",
      "\n",
      "   team_2_name  team_id    team_name rank_during  \n",
      "0  Corinthians    11814  Corinthians         125  \n",
      "1  Corinthians    12318      Intense         169  \n",
      "2  Corinthians    11814  Corinthians         125  \n",
      "3  Corinthians    12318      Intense         169  \n",
      "4  Corinthians    11814  Corinthians         125  \n",
      "\n",
      "Columns: ['id_demo_exports', 'match_id', 'event_id', 'team_1_id', 'team_2_id', 'team_1_name', 'team_2_name', 'team_id', 'team_name', 'rank_during']\n",
      "Unique teams with rankings: 110\n",
      "Ranking range: 10 - 99\n"
     ]
    }
   ],
   "source": [
    "# 1.2 Team Ranking Analysis - Explore Available Team Data\n",
    "\n",
    "print(\"üèÜ EXPLORING TEAM RANKING DATA\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# First, let's explore what team data is available\n",
    "team_info_query = \"\"\"\n",
    "SELECT DISTINCT\n",
    "    r.id_demo_exports,\n",
    "    r.match_id,\n",
    "    r.event_id,\n",
    "    hmi.team_1_id,\n",
    "    hmi.team_2_id,\n",
    "    hmi.team_1_name,\n",
    "    hmi.team_2_name,\n",
    "    het.team_id,\n",
    "    het.team_name,\n",
    "    het.rank_during\n",
    "FROM rounds_ed r\n",
    "LEFT JOIN hltv_match_info hmi ON r.match_id = hmi.match_id\n",
    "LEFT JOIN hltv_events_teams het ON (het.team_id = hmi.team_1_id or het.team_id = hmi.team_2_id)\n",
    "    AND het.event_id = r.event_id\n",
    "WHERE r.event_id IS NOT NULL\n",
    "    AND hmi.team_1_id IS NOT NULL\n",
    "    AND hmi.team_2_id IS NOT NULL\n",
    "    AND het.rank_during IS NOT NULL\n",
    "ORDER BY r.id_demo_exports\n",
    "LIMIT 1000\n",
    "\"\"\"\n",
    "\n",
    "print(\"üîç Querying team ranking information...\")\n",
    "try:\n",
    "    team_ranking_data = pd.read_sql(team_info_query, conn)\n",
    "    print(f\"üìä Found {len(team_ranking_data):,} rounds with team ranking data\")\n",
    "    \n",
    "    if len(team_ranking_data) > 0:\n",
    "        print(\"\\nüîç Team ranking data preview:\")\n",
    "        print(team_ranking_data.head())\n",
    "        print(f\"\\nColumns: {list(team_ranking_data.columns)}\")\n",
    "        print(f\"Unique teams with rankings: {team_ranking_data['team_id'].nunique()}\")\n",
    "        print(f\"Ranking range: {team_ranking_data['rank_during'].min()} - {team_ranking_data['rank_during'].max()}\")\n",
    "    else:\n",
    "        print(\"‚ùå No team ranking data found\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error querying team ranking data: {e}\")\n",
    "    print(\"Will proceed without team ranking controls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0426e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Querying comprehensive team data with rankings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peter\\AppData\\Local\\Temp\\ipykernel_28844\\4279112029.py:70: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  enhanced_team_data = pd.read_sql(team_ranking_comprehensive_query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Retrieved 2,601,262 team rounds\n",
      "üìà Rounds with ranking data: 1,822,909 (70.1%)\n",
      "‚úÖ Enhanced dataset prepared for rank-controlled analysis\n"
     ]
    }
   ],
   "source": [
    "# 1.3 Enhanced Team Equipment Analysis with HLTV Ranking Controls\n",
    "\n",
    "# Query comprehensive team data with ranking information\n",
    "team_ranking_comprehensive_query = \"\"\"\n",
    "WITH team_round_data AS (\n",
    "    SELECT \n",
    "        r.id as round_id,\n",
    "        r.id_demo_exports,\n",
    "        r.round_num,\n",
    "        r.team1_winner,\n",
    "        r.ct_winner,\n",
    "        r.match_id,\n",
    "        r.event_id,\n",
    "        -- Team 1 data\n",
    "        AVG(CASE WHEN pr.team = 1 THEN pr.eq_val_fte END) as t1_avg_eq_val_fte,\n",
    "        SUM(CASE WHEN pr.team = 1 THEN pe.money_spent END) as t1_total_spent,\n",
    "        COUNT(CASE WHEN pr.team = 1 THEN 1 END) as t1_players,\n",
    "        -- Team 2 data  \n",
    "        AVG(CASE WHEN pr.team = 2 THEN pr.eq_val_fte END) as t2_avg_eq_val_fte,\n",
    "        SUM(CASE WHEN pr.team = 2 THEN pe.money_spent END) as t2_total_spent,\n",
    "        COUNT(CASE WHEN pr.team = 2 THEN 1 END) as t2_players,\n",
    "        -- Round end analysis\n",
    "        COUNT(CASE WHEN pr.team = 1 AND pr.is_alive_re = true THEN 1 END) as t1_survivors,\n",
    "        COUNT(CASE WHEN pr.team = 2 AND pr.is_alive_re = true THEN 1 END) as t2_survivors,\n",
    "        -- Equipment saved\n",
    "        SUM(CASE WHEN pr.team = 1 AND pr.is_alive_re = true THEN pr.eq_val_re END) as t1_saved_eq,\n",
    "        SUM(CASE WHEN pr.team = 2 AND pr.is_alive_re = true THEN pr.eq_val_re END) as t2_saved_eq\n",
    "    FROM rounds_ed r\n",
    "    JOIN player_round_ed pr ON r.id = pr.round_id\n",
    "    LEFT JOIN player_economy_ed pe ON pr.id = pe.player_round_id\n",
    "    WHERE r.team1_winner IS NOT NULL\n",
    "        AND pr.team IN (1, 2)\n",
    "        AND pr.eq_val_fte IS NOT NULL\n",
    "    GROUP BY r.id, r.id_demo_exports, r.round_num, r.team1_winner, r.ct_winner, r.match_id, r.event_id\n",
    "    HAVING COUNT(CASE WHEN pr.team = 1 THEN 1 END) = 5 \n",
    "       AND COUNT(CASE WHEN pr.team = 2 THEN 1 END) = 5\n",
    "),\n",
    "team_rankings AS (\n",
    "    SELECT DISTINCT\n",
    "        hmi.match_id,\n",
    "        hmi.team_1_id,\n",
    "        hmi.team_2_id,\n",
    "        hmi.team_1_name,\n",
    "        hmi.team_2_name,\n",
    "        CAST(het1.rank_during AS INTEGER) as t1_ranking,\n",
    "        CAST(het2.rank_during AS INTEGER) as t2_ranking\n",
    "    FROM hltv_match_info hmi\n",
    "    LEFT JOIN hltv_events_teams het1 ON het1.team_id = hmi.team_1_id AND het1.event_id = hmi.event_id\n",
    "    LEFT JOIN hltv_events_teams het2 ON het2.team_id = hmi.team_2_id AND het2.event_id = hmi.event_id\n",
    "    WHERE het1.rank_during IS NOT NULL AND het2.rank_during IS NOT NULL\n",
    ")\n",
    "SELECT \n",
    "    trd.*,\n",
    "    tr.t1_ranking,\n",
    "    tr.t2_ranking,\n",
    "    tr.team_1_name,\n",
    "    tr.team_2_name,\n",
    "    -- Calculate ranking advantage (lower ranking number = better)\n",
    "    (tr.t2_ranking - tr.t1_ranking) as ranking_advantage_t1,\n",
    "    -- Equipment advantage\n",
    "    (trd.t1_avg_eq_val_fte - trd.t2_avg_eq_val_fte) as eq_advantage_t1,\n",
    "    (trd.t1_total_spent - trd.t2_total_spent) as spending_advantage_t1\n",
    "FROM team_round_data trd\n",
    "LEFT JOIN team_rankings tr ON trd.match_id = tr.match_id\n",
    "WHERE trd.t1_avg_eq_val_fte IS NOT NULL \n",
    "    AND trd.t2_avg_eq_val_fte IS NOT NULL\n",
    "\"\"\"\n",
    "\n",
    "print(\"üîç Querying comprehensive team data with rankings...\")\n",
    "enhanced_team_data = pd.read_sql(team_ranking_comprehensive_query, conn)\n",
    "print(f\"üìä Retrieved {len(enhanced_team_data):,} team rounds\")\n",
    "\n",
    "# Check ranking data availability\n",
    "ranking_available = enhanced_team_data['t1_ranking'].notna().sum()\n",
    "print(f\"üìà Rounds with ranking data: {ranking_available:,} ({ranking_available/len(enhanced_team_data)*100:.1f}%)\")\n",
    "\n",
    "# Store for later use\n",
    "print(f\"‚úÖ Enhanced dataset prepared for rank-controlled analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a27a5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ RANK-CONTROLLED WIN PROBABILITY ANALYSIS\n",
      "============================================================\n",
      "Analyzing 1,822,909 rounds with complete ranking data\n",
      "\n",
      "üèÜ TEAM SKILL DISTRIBUTION\n",
      "===================================\n",
      "Outside Top 50: 2,071,689 team instances\n",
      "Top 50: 675,394 team instances\n",
      "Top 30: 663,138 team instances\n",
      "Top 10: 235,597 team instances\n",
      "\n",
      "‚öñÔ∏è SAME-TIER MATCHUPS (FAIR COMPETITION)\n",
      "==================================================\n",
      "\n",
      "üèÜ TEAM SKILL DISTRIBUTION\n",
      "===================================\n",
      "Outside Top 50: 2,071,689 team instances\n",
      "Top 50: 675,394 team instances\n",
      "Top 30: 663,138 team instances\n",
      "Top 10: 235,597 team instances\n",
      "\n",
      "‚öñÔ∏è SAME-TIER MATCHUPS (FAIR COMPETITION)\n",
      "==================================================\n",
      "Sample size: 1,029,978 rounds\n",
      "\\nWin rates by equipment advantage (same skill tier):\n",
      "                                    Count  T1_Win_Rate  Avg_Eq_Advantage  \\\n",
      "t1_skill_tier  eq_advantage_bins                                           \n",
      "Outside Top 50 T1 Behind           235256        0.267         -2969.064   \n",
      "               T1 Slightly Behind   58912        0.472          -741.393   \n",
      "               Balanced            181075        0.508             3.527   \n",
      "               T1 Slightly Ahead    59402        0.545           752.886   \n",
      "               T1 Ahead            247398        0.745          2991.425   \n",
      "Top 10         T1 Behind            13188        0.271         -2898.048   \n",
      "               T1 Slightly Behind    3493        0.475          -743.324   \n",
      "               Balanced             10202        0.499             4.703   \n",
      "               T1 Slightly Ahead     3266        0.554           748.977   \n",
      "               T1 Ahead             13308        0.739          2927.556   \n",
      "Top 30         T1 Behind            36467        0.270         -2952.698   \n",
      "               T1 Slightly Behind    8998        0.464          -740.699   \n",
      "               Balanced             27178        0.500             1.195   \n",
      "               T1 Slightly Ahead     9057        0.544           753.044   \n",
      "               T1 Ahead             37222        0.740          2977.050   \n",
      "Top 50         T1 Behind            26556        0.272         -2966.041   \n",
      "               T1 Slightly Behind    6432        0.455          -739.998   \n",
      "               Balanced             19588        0.499             5.896   \n",
      "               T1 Slightly Ahead     6439        0.528           751.899   \n",
      "               T1 Ahead             26541        0.735          2958.848   \n",
      "\n",
      "                                   T1_Survivors  T2_Survivors  \n",
      "t1_skill_tier  eq_advantage_bins                               \n",
      "Outside Top 50 T1 Behind                  1.404         2.678  \n",
      "               T1 Slightly Behind         1.768         2.022  \n",
      "               Balanced                   1.887         1.854  \n",
      "               T1 Slightly Ahead          2.065         1.724  \n",
      "               T1 Ahead                   2.725         1.378  \n",
      "Top 10         T1 Behind                  1.444         2.754  \n",
      "               T1 Slightly Behind         1.836         2.101  \n",
      "               Balanced                   1.910         1.917  \n",
      "               T1 Slightly Ahead          2.131         1.774  \n",
      "               T1 Ahead                   2.779         1.435  \n",
      "Top 30         T1 Behind                  1.426         2.709  \n",
      "               T1 Slightly Behind         1.791         2.075  \n",
      "               Balanced                   1.905         1.895  \n",
      "               T1 Slightly Ahead          2.106         1.768  \n",
      "               T1 Ahead                   2.745         1.412  \n",
      "Top 50         T1 Behind                  1.439         2.700  \n",
      "               T1 Slightly Behind         1.781         2.071  \n",
      "               Balanced                   1.883         1.894  \n",
      "               T1 Slightly Ahead          2.048         1.779  \n",
      "               T1 Ahead                   2.724         1.424  \n",
      "\\nEquipment advantage correlation (same tier): 0.4229\n",
      "Sample size: 1,029,978 rounds\n",
      "\\nWin rates by equipment advantage (same skill tier):\n",
      "                                    Count  T1_Win_Rate  Avg_Eq_Advantage  \\\n",
      "t1_skill_tier  eq_advantage_bins                                           \n",
      "Outside Top 50 T1 Behind           235256        0.267         -2969.064   \n",
      "               T1 Slightly Behind   58912        0.472          -741.393   \n",
      "               Balanced            181075        0.508             3.527   \n",
      "               T1 Slightly Ahead    59402        0.545           752.886   \n",
      "               T1 Ahead            247398        0.745          2991.425   \n",
      "Top 10         T1 Behind            13188        0.271         -2898.048   \n",
      "               T1 Slightly Behind    3493        0.475          -743.324   \n",
      "               Balanced             10202        0.499             4.703   \n",
      "               T1 Slightly Ahead     3266        0.554           748.977   \n",
      "               T1 Ahead             13308        0.739          2927.556   \n",
      "Top 30         T1 Behind            36467        0.270         -2952.698   \n",
      "               T1 Slightly Behind    8998        0.464          -740.699   \n",
      "               Balanced             27178        0.500             1.195   \n",
      "               T1 Slightly Ahead     9057        0.544           753.044   \n",
      "               T1 Ahead             37222        0.740          2977.050   \n",
      "Top 50         T1 Behind            26556        0.272         -2966.041   \n",
      "               T1 Slightly Behind    6432        0.455          -739.998   \n",
      "               Balanced             19588        0.499             5.896   \n",
      "               T1 Slightly Ahead     6439        0.528           751.899   \n",
      "               T1 Ahead             26541        0.735          2958.848   \n",
      "\n",
      "                                   T1_Survivors  T2_Survivors  \n",
      "t1_skill_tier  eq_advantage_bins                               \n",
      "Outside Top 50 T1 Behind                  1.404         2.678  \n",
      "               T1 Slightly Behind         1.768         2.022  \n",
      "               Balanced                   1.887         1.854  \n",
      "               T1 Slightly Ahead          2.065         1.724  \n",
      "               T1 Ahead                   2.725         1.378  \n",
      "Top 10         T1 Behind                  1.444         2.754  \n",
      "               T1 Slightly Behind         1.836         2.101  \n",
      "               Balanced                   1.910         1.917  \n",
      "               T1 Slightly Ahead          2.131         1.774  \n",
      "               T1 Ahead                   2.779         1.435  \n",
      "Top 30         T1 Behind                  1.426         2.709  \n",
      "               T1 Slightly Behind         1.791         2.075  \n",
      "               Balanced                   1.905         1.895  \n",
      "               T1 Slightly Ahead          2.106         1.768  \n",
      "               T1 Ahead                   2.745         1.412  \n",
      "Top 50         T1 Behind                  1.439         2.700  \n",
      "               T1 Slightly Behind         1.781         2.071  \n",
      "               Balanced                   1.883         1.894  \n",
      "               T1 Slightly Ahead          2.048         1.779  \n",
      "               T1 Ahead                   2.724         1.424  \n",
      "\\nEquipment advantage correlation (same tier): 0.4229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peter\\AppData\\Local\\Temp\\ipykernel_28844\\4135482629.py:45: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  tier_analysis = same_tier_matches.groupby(['t1_skill_tier', 'eq_advantage_bins']).agg({\n"
     ]
    }
   ],
   "source": [
    "# 1.4 Rank-Controlled Win Probability Analysis\n",
    "\n",
    "if ranking_available > 0:\n",
    "    # Create ranking-controlled dataset\n",
    "    ranked_data = enhanced_team_data.dropna(subset=['t1_ranking', 't2_ranking']).copy()\n",
    "    print(f\"üéØ RANK-CONTROLLED WIN PROBABILITY ANALYSIS\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Analyzing {len(ranked_data):,} rounds with complete ranking data\")\n",
    "    \n",
    "    # Categorize team skill levels\n",
    "    def categorize_ranking(ranking):\n",
    "        if ranking <= 10:\n",
    "            return 'Top 10'\n",
    "        elif ranking <= 30:\n",
    "            return 'Top 30'\n",
    "        elif ranking <= 50:\n",
    "            return 'Top 50'\n",
    "        else:\n",
    "            return 'Outside Top 50'\n",
    "    \n",
    "    ranked_data['t1_skill_tier'] = ranked_data['t1_ranking'].apply(categorize_ranking)\n",
    "    ranked_data['t2_skill_tier'] = ranked_data['t2_ranking'].apply(categorize_ranking)\n",
    "    \n",
    "    print(f\"\\nüèÜ TEAM SKILL DISTRIBUTION\")\n",
    "    print(\"=\" * 35)\n",
    "    skill_dist = pd.concat([ranked_data['t1_skill_tier'], ranked_data['t2_skill_tier']]).value_counts()\n",
    "    for tier, count in skill_dist.items():\n",
    "        print(f\"{tier}: {count:,} team instances\")\n",
    "    \n",
    "    # 1. Same-tier matchup analysis (fair competition)\n",
    "    print(f\"\\n‚öñÔ∏è SAME-TIER MATCHUPS (FAIR COMPETITION)\")\n",
    "    print(\"=\" * 50)\n",
    "    same_tier_matches = ranked_data[ranked_data['t1_skill_tier'] == ranked_data['t2_skill_tier']].copy()\n",
    "    \n",
    "    if len(same_tier_matches) > 0:\n",
    "        print(f\"Sample size: {len(same_tier_matches):,} rounds\")\n",
    "        \n",
    "        # Equipment advantage analysis within same skill tiers\n",
    "        same_tier_matches['eq_advantage_bins'] = pd.cut(\n",
    "            same_tier_matches['eq_advantage_t1'], \n",
    "            bins=[-np.inf, -1000, -500, 500, 1000, np.inf],\n",
    "            labels=['T1 Behind', 'T1 Slightly Behind', 'Balanced', 'T1 Slightly Ahead', 'T1 Ahead']\n",
    "        )\n",
    "        \n",
    "        tier_analysis = same_tier_matches.groupby(['t1_skill_tier', 'eq_advantage_bins']).agg({\n",
    "            'team1_winner': ['count', 'mean'],\n",
    "            'eq_advantage_t1': 'mean',\n",
    "            't1_survivors': 'mean',\n",
    "            't2_survivors': 'mean'\n",
    "        }).round(3)\n",
    "        \n",
    "        tier_analysis.columns = ['Count', 'T1_Win_Rate', 'Avg_Eq_Advantage', 'T1_Survivors', 'T2_Survivors']\n",
    "        print(\"\\\\nWin rates by equipment advantage (same skill tier):\")\n",
    "        print(tier_analysis.head(20))\n",
    "        \n",
    "        # Overall equipment impact within same tiers\n",
    "        same_tier_corr = same_tier_matches['eq_advantage_t1'].corr(same_tier_matches['team1_winner'])\n",
    "        print(f\"\\\\nEquipment advantage correlation (same tier): {same_tier_corr:.4f}\")\n",
    "        \n",
    "        # Store same-tier data for controlled probabilities\n",
    "        controlled_data = same_tier_matches\n",
    "    else:\n",
    "        print(\"‚ùå Insufficient same-tier matchup data\")\n",
    "        controlled_data = ranked_data\n",
    "        \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Limited HLTV ranking data available - using equipment-based skill proxy\")\n",
    "    ranked_data = enhanced_team_data.copy()\n",
    "    \n",
    "    # Create skill proxy based on average equipment spending\n",
    "    ranked_data['t1_skill_proxy'] = pd.qcut(ranked_data['t1_avg_eq_val_fte'], \n",
    "                                           q=4, labels=['Low', 'Medium-Low', 'Medium-High', 'High'])\n",
    "    ranked_data['t2_skill_proxy'] = pd.qcut(ranked_data['t2_avg_eq_val_fte'], \n",
    "                                           q=4, labels=['Low', 'Medium-Low', 'Medium-High', 'High'])\n",
    "    controlled_data = ranked_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "426a4ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü•ä CROSS-TIER MATCHUP ANALYSIS\n",
      "========================================\n",
      "Team matchups (T1 vs T2 skill tiers):\n",
      "                                Count  T1_Win_Rate  Avg_Eq_Advantage  \\\n",
      "t1_skill_tier  t2_skill_tier                                           \n",
      "Outside Top 50 Outside Top 50  782043        0.511            55.326   \n",
      "               Top 10            3992        0.418          -394.704   \n",
      "               Top 30           54062        0.443          -276.781   \n",
      "               Top 50          119139        0.466          -163.502   \n",
      "Top 10         Outside Top 50   13814        0.601           482.261   \n",
      "               Top 10           43457        0.505            14.685   \n",
      "               Top 30           63407        0.532           127.222   \n",
      "               Top 50           19840        0.563           285.083   \n",
      "Top 30         Outside Top 50  114752        0.565           304.640   \n",
      "               Top 10           38622        0.469          -140.785   \n",
      "               Top 30          118922        0.505            27.949   \n",
      "               Top 50           92759        0.528           142.741   \n",
      "Top 50         Outside Top 50  201844        0.544           209.762   \n",
      "               Top 10            9008        0.447          -255.350   \n",
      "               Top 30           61692        0.477          -109.159   \n",
      "\n",
      "                               T1_Survivors  T2_Survivors  T1_Avg_Rank  \\\n",
      "t1_skill_tier  t2_skill_tier                                             \n",
      "Outside Top 50 Outside Top 50         2.011         1.954      114.824   \n",
      "               Top 10                 1.821         2.232       77.455   \n",
      "               Top 30                 1.862         2.153       85.095   \n",
      "               Top 50                 1.913         2.076       90.545   \n",
      "Top 10         Outside Top 50         2.267         1.771        6.013   \n",
      "               Top 10                 2.045         2.027        4.943   \n",
      "               Top 30                 2.105         1.957        5.706   \n",
      "               Top 50                 2.177         1.870        5.873   \n",
      "Top 30         Outside Top 50         2.166         1.851       22.663   \n",
      "               Top 10                 1.949         2.098       17.949   \n",
      "               Top 30                 2.028         1.997       19.723   \n",
      "               Top 50                 2.082         1.937       21.902   \n",
      "Top 50         Outside Top 50         2.108         1.890       40.900   \n",
      "               Top 10                 1.882         2.168       38.419   \n",
      "               Top 30                 1.961         2.068       39.173   \n",
      "\n",
      "                               T2_Avg_Rank  \n",
      "t1_skill_tier  t2_skill_tier                \n",
      "Outside Top 50 Outside Top 50      123.713  \n",
      "               Top 10                6.191  \n",
      "               Top 30               23.503  \n",
      "               Top 50               41.001  \n",
      "Top 10         Outside Top 50       87.237  \n",
      "               Top 10                5.615  \n",
      "               Top 30               18.187  \n",
      "               Top 50               38.847  \n",
      "Top 30         Outside Top 50       89.194  \n",
      "               Top 10                6.036  \n",
      "               Top 30               21.027  \n",
      "               Top 50               39.500  \n",
      "Top 50         Outside Top 50       93.684  \n",
      "               Top 10                6.384  \n",
      "               Top 30               22.333  \n",
      "\n",
      "üìä SKILL ADVANTAGE IMPACT ON WIN RATES\n",
      "=============================================\n",
      "Team matchups (T1 vs T2 skill tiers):\n",
      "                                Count  T1_Win_Rate  Avg_Eq_Advantage  \\\n",
      "t1_skill_tier  t2_skill_tier                                           \n",
      "Outside Top 50 Outside Top 50  782043        0.511            55.326   \n",
      "               Top 10            3992        0.418          -394.704   \n",
      "               Top 30           54062        0.443          -276.781   \n",
      "               Top 50          119139        0.466          -163.502   \n",
      "Top 10         Outside Top 50   13814        0.601           482.261   \n",
      "               Top 10           43457        0.505            14.685   \n",
      "               Top 30           63407        0.532           127.222   \n",
      "               Top 50           19840        0.563           285.083   \n",
      "Top 30         Outside Top 50  114752        0.565           304.640   \n",
      "               Top 10           38622        0.469          -140.785   \n",
      "               Top 30          118922        0.505            27.949   \n",
      "               Top 50           92759        0.528           142.741   \n",
      "Top 50         Outside Top 50  201844        0.544           209.762   \n",
      "               Top 10            9008        0.447          -255.350   \n",
      "               Top 30           61692        0.477          -109.159   \n",
      "\n",
      "                               T1_Survivors  T2_Survivors  T1_Avg_Rank  \\\n",
      "t1_skill_tier  t2_skill_tier                                             \n",
      "Outside Top 50 Outside Top 50         2.011         1.954      114.824   \n",
      "               Top 10                 1.821         2.232       77.455   \n",
      "               Top 30                 1.862         2.153       85.095   \n",
      "               Top 50                 1.913         2.076       90.545   \n",
      "Top 10         Outside Top 50         2.267         1.771        6.013   \n",
      "               Top 10                 2.045         2.027        4.943   \n",
      "               Top 30                 2.105         1.957        5.706   \n",
      "               Top 50                 2.177         1.870        5.873   \n",
      "Top 30         Outside Top 50         2.166         1.851       22.663   \n",
      "               Top 10                 1.949         2.098       17.949   \n",
      "               Top 30                 2.028         1.997       19.723   \n",
      "               Top 50                 2.082         1.937       21.902   \n",
      "Top 50         Outside Top 50         2.108         1.890       40.900   \n",
      "               Top 10                 1.882         2.168       38.419   \n",
      "               Top 30                 1.961         2.068       39.173   \n",
      "\n",
      "                               T2_Avg_Rank  \n",
      "t1_skill_tier  t2_skill_tier                \n",
      "Outside Top 50 Outside Top 50      123.713  \n",
      "               Top 10                6.191  \n",
      "               Top 30               23.503  \n",
      "               Top 50               41.001  \n",
      "Top 10         Outside Top 50       87.237  \n",
      "               Top 10                5.615  \n",
      "               Top 30               18.187  \n",
      "               Top 50               38.847  \n",
      "Top 30         Outside Top 50       89.194  \n",
      "               Top 10                6.036  \n",
      "               Top 30               21.027  \n",
      "               Top 50               39.500  \n",
      "Top 50         Outside Top 50       93.684  \n",
      "               Top 10                6.384  \n",
      "               Top 30               22.333  \n",
      "\n",
      "üìä SKILL ADVANTAGE IMPACT ON WIN RATES\n",
      "=============================================\n",
      "          T1_Tier         T2_Tier  Sample_Size  T1_Win_Rate  Avg_Rank_Diff  \\\n",
      "0          Top 10          Top 30        63407        0.532         12.481   \n",
      "1          Top 10          Top 50        19840        0.563         32.974   \n",
      "2          Top 10  Outside Top 50        13814        0.601         81.224   \n",
      "3          Top 30          Top 10        38622        0.469        -11.913   \n",
      "4          Top 30          Top 50        92759        0.528         17.598   \n",
      "5          Top 30  Outside Top 50       114752        0.565         66.531   \n",
      "6          Top 50          Top 10         9008        0.447        -32.035   \n",
      "7          Top 50          Top 30        61692        0.477        -16.841   \n",
      "8          Top 50  Outside Top 50       201844        0.544         52.784   \n",
      "9  Outside Top 50          Top 10         3992        0.418        -71.264   \n",
      "\n",
      "   Eq_Advantage_Impact  \n",
      "0                0.415  \n",
      "1                0.422  \n",
      "2                0.417  \n",
      "3                0.420  \n",
      "4                0.420  \n",
      "5                0.419  \n",
      "6                0.414  \n",
      "7                0.420  \n",
      "8                0.419  \n",
      "9                0.405  \n",
      "\n",
      "üéØ KEY INSIGHTS FOR ABM:\n",
      "==============================\n",
      "When better team (T1) plays weaker team:\n",
      "  Average win rate: 0.453\n",
      "  Equipment advantage matters less: 0.416\n",
      "When weaker team (T1) plays better team:\n",
      "  Average win rate: 0.555\n",
      "  Equipment advantage matters more: 0.419\n",
      "          T1_Tier         T2_Tier  Sample_Size  T1_Win_Rate  Avg_Rank_Diff  \\\n",
      "0          Top 10          Top 30        63407        0.532         12.481   \n",
      "1          Top 10          Top 50        19840        0.563         32.974   \n",
      "2          Top 10  Outside Top 50        13814        0.601         81.224   \n",
      "3          Top 30          Top 10        38622        0.469        -11.913   \n",
      "4          Top 30          Top 50        92759        0.528         17.598   \n",
      "5          Top 30  Outside Top 50       114752        0.565         66.531   \n",
      "6          Top 50          Top 10         9008        0.447        -32.035   \n",
      "7          Top 50          Top 30        61692        0.477        -16.841   \n",
      "8          Top 50  Outside Top 50       201844        0.544         52.784   \n",
      "9  Outside Top 50          Top 10         3992        0.418        -71.264   \n",
      "\n",
      "   Eq_Advantage_Impact  \n",
      "0                0.415  \n",
      "1                0.422  \n",
      "2                0.417  \n",
      "3                0.420  \n",
      "4                0.420  \n",
      "5                0.419  \n",
      "6                0.414  \n",
      "7                0.420  \n",
      "8                0.419  \n",
      "9                0.405  \n",
      "\n",
      "üéØ KEY INSIGHTS FOR ABM:\n",
      "==============================\n",
      "When better team (T1) plays weaker team:\n",
      "  Average win rate: 0.453\n",
      "  Equipment advantage matters less: 0.416\n",
      "When weaker team (T1) plays better team:\n",
      "  Average win rate: 0.555\n",
      "  Equipment advantage matters more: 0.419\n"
     ]
    }
   ],
   "source": [
    "# 1.5 Cross-Tier Matchup Analysis (Skill Gap Impact)\n",
    "\n",
    "if ranking_available > 0:\n",
    "    print(f\"\\nü•ä CROSS-TIER MATCHUP ANALYSIS\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    cross_tier_analysis = ranked_data.groupby(['t1_skill_tier', 't2_skill_tier']).agg({\n",
    "        'team1_winner': ['count', 'mean'],\n",
    "        'eq_advantage_t1': 'mean',\n",
    "        't1_survivors': 'mean',\n",
    "        't2_survivors': 'mean',\n",
    "        't1_ranking': 'mean',\n",
    "        't2_ranking': 'mean'\n",
    "    }).round(3)\n",
    "    \n",
    "    cross_tier_analysis.columns = ['Count', 'T1_Win_Rate', 'Avg_Eq_Advantage', 'T1_Survivors', 'T2_Survivors', 'T1_Avg_Rank', 'T2_Avg_Rank']\n",
    "    print(\"Team matchups (T1 vs T2 skill tiers):\")\n",
    "    print(cross_tier_analysis.head(15))\n",
    "    \n",
    "    # Calculate skill advantage impact\n",
    "    print(f\"\\nüìä SKILL ADVANTAGE IMPACT ON WIN RATES\")\n",
    "    print(\"=\" * 45)\n",
    "    \n",
    "    # When high-ranked team (lower number) plays lower-ranked team\n",
    "    skill_advantage_analysis = []\n",
    "    \n",
    "    for t1_tier in ['Top 10', 'Top 30', 'Top 50', 'Outside Top 50']:\n",
    "        for t2_tier in ['Top 10', 'Top 30', 'Top 50', 'Outside Top 50']:\n",
    "            if t1_tier != t2_tier:  # Cross-tier only\n",
    "                subset = ranked_data[(ranked_data['t1_skill_tier'] == t1_tier) & \n",
    "                                   (ranked_data['t2_skill_tier'] == t2_tier)]\n",
    "                if len(subset) > 10:  # Minimum sample size\n",
    "                    skill_advantage_analysis.append({\n",
    "                        'T1_Tier': t1_tier,\n",
    "                        'T2_Tier': t2_tier,\n",
    "                        'Sample_Size': len(subset),\n",
    "                        'T1_Win_Rate': subset['team1_winner'].mean(),\n",
    "                        'Avg_Rank_Diff': subset['ranking_advantage_t1'].mean(),\n",
    "                        'Eq_Advantage_Impact': subset['eq_advantage_t1'].corr(subset['team1_winner'])\n",
    "                    })\n",
    "    \n",
    "    skill_df = pd.DataFrame(skill_advantage_analysis)\n",
    "    if len(skill_df) > 0:\n",
    "        skill_df = skill_df.round(3)\n",
    "        print(skill_df.head(10))\n",
    "        \n",
    "        # Key insights for ABM\n",
    "        print(f\"\\nüéØ KEY INSIGHTS FOR ABM:\")\n",
    "        print(\"=\" * 30)\n",
    "        \n",
    "        # Impact of playing against better teams\n",
    "        higher_vs_lower = skill_df[skill_df['Avg_Rank_Diff'] < -5]  # T1 much better than T2\n",
    "        lower_vs_higher = skill_df[skill_df['Avg_Rank_Diff'] > 5]   # T1 much worse than T2\n",
    "        \n",
    "        if len(higher_vs_lower) > 0:\n",
    "            print(f\"When better team (T1) plays weaker team:\")\n",
    "            print(f\"  Average win rate: {higher_vs_lower['T1_Win_Rate'].mean():.3f}\")\n",
    "            print(f\"  Equipment advantage matters less: {higher_vs_lower['Eq_Advantage_Impact'].mean():.3f}\")\n",
    "            \n",
    "        if len(lower_vs_higher) > 0:\n",
    "            print(f\"When weaker team (T1) plays better team:\")\n",
    "            print(f\"  Average win rate: {lower_vs_higher['T1_Win_Rate'].mean():.3f}\")\n",
    "            print(f\"  Equipment advantage matters more: {lower_vs_higher['Eq_Advantage_Impact'].mean():.3f}\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Using equipment-based skill proxy for cross-tier analysis\")\n",
    "    \n",
    "    # Equipment-based cross analysis\n",
    "    cross_eq_analysis = ranked_data.groupby(['t1_skill_proxy', 't2_skill_proxy']).agg({\n",
    "        'team1_winner': ['count', 'mean'],\n",
    "        'eq_advantage_t1': 'mean',\n",
    "        't1_survivors': 'mean',\n",
    "        't2_survivors': 'mean'\n",
    "    }).round(3)\n",
    "    \n",
    "    cross_eq_analysis.columns = ['Count', 'T1_Win_Rate', 'Avg_Eq_Advantage', 'T1_Survivors', 'T2_Survivors']\n",
    "    print(\"Equipment-based skill matchups:\")\n",
    "    print(cross_eq_analysis.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9144983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üë• RANK-CONTROLLED SURVIVOR DISTRIBUTIONS\n",
      "==================================================\n",
      "Team 1 Winners (rank-controlled):\n",
      "T1 Survivors - Mean: 2.99, Std: 1.25\n",
      "T2 Survivors - Mean: 1.01, Std: 0.59\n",
      "\\nTeam 2 Winners (rank-controlled):\n",
      "T1 Survivors - Mean: 1.01, Std: 0.59\n",
      "T2 Survivors - Mean: 2.96, Std: 1.25\n",
      "\n",
      "üèÜ SURVIVOR ANALYSIS BY SKILL TIER\n",
      "========================================\n",
      "Survivor averages by skill tier and outcome:\n",
      "                             t1_survivors  t2_survivors\n",
      "t1_skill_tier  team1_winner                            \n",
      "Outside Top 50 False                 1.00          2.95\n",
      "               True                  2.98          1.00\n",
      "Top 10         False                 1.05          3.03\n",
      "               True                  3.02          1.05\n",
      "Top 30         False                 1.02          2.99\n",
      "               True                  3.02          1.03\n",
      "Top 50         False                 1.02          2.98\n",
      "               True                  3.00          1.03\n",
      "\n",
      "üìä DETAILED SURVIVOR COUNT DISTRIBUTIONS (RANK-CONTROLLED)\n",
      "=================================================================\n",
      "Winning team survivors distribution (rank-controlled):\n",
      "  0 survivors: 8,740 (0.8%)\n",
      "  1 survivors: 134,532 (13.1%)\n",
      "  2 survivors: 233,350 (22.7%)\n",
      "  3 survivors: 280,005 (27.2%)\n",
      "  4 survivors: 246,736 (24.0%)\n",
      "  5 survivors: 126,615 (12.3%)\n",
      "\\nLosing team survivors distribution (rank-controlled):\n",
      "  0 survivors: 124,250 (12.1%)\n",
      "  1 survivors: 812,812 (78.9%)\n",
      "  2 survivors: 60,700 (5.9%)\n",
      "  3 survivors: 25,327 (2.5%)\n",
      "  4 survivors: 5,815 (0.6%)\n",
      "  5 survivors: 1,074 (0.1%)\n",
      "\n",
      "üé≤ ABM PARAMETERS - RANK-CONTROLLED SURVIVOR DISTRIBUTIONS\n",
      "=================================================================\n",
      "Winning team average survivors: 2.97\n",
      "Losing team average survivors: 1.01\n",
      "Winning team survivor std dev: 1.25\n",
      "Losing team survivor std dev: 0.59\n",
      "Winning team survivors distribution (rank-controlled):\n",
      "  0 survivors: 8,740 (0.8%)\n",
      "  1 survivors: 134,532 (13.1%)\n",
      "  2 survivors: 233,350 (22.7%)\n",
      "  3 survivors: 280,005 (27.2%)\n",
      "  4 survivors: 246,736 (24.0%)\n",
      "  5 survivors: 126,615 (12.3%)\n",
      "\\nLosing team survivors distribution (rank-controlled):\n",
      "  0 survivors: 124,250 (12.1%)\n",
      "  1 survivors: 812,812 (78.9%)\n",
      "  2 survivors: 60,700 (5.9%)\n",
      "  3 survivors: 25,327 (2.5%)\n",
      "  4 survivors: 5,815 (0.6%)\n",
      "  5 survivors: 1,074 (0.1%)\n",
      "\n",
      "üé≤ ABM PARAMETERS - RANK-CONTROLLED SURVIVOR DISTRIBUTIONS\n",
      "=================================================================\n",
      "Winning team average survivors: 2.97\n",
      "Losing team average survivors: 1.01\n",
      "Winning team survivor std dev: 1.25\n",
      "Losing team survivor std dev: 0.59\n"
     ]
    }
   ],
   "source": [
    "# 1.6 Rank-Controlled Survivor Distribution Analysis\n",
    "\n",
    "print(f\"\\nüë• RANK-CONTROLLED SURVIVOR DISTRIBUTIONS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Use rank-controlled data for more accurate distributions\n",
    "analysis_data = controlled_data if 'controlled_data' in locals() else enhanced_team_data\n",
    "\n",
    "# Distribution of survivors by winning team (rank-controlled)\n",
    "survivors_analysis = analysis_data.groupby(['team1_winner']).agg({\n",
    "    't1_survivors': ['mean', 'std', 'min', 'max'],\n",
    "    't2_survivors': ['mean', 'std', 'min', 'max']\n",
    "}).round(2)\n",
    "\n",
    "print(\"Team 1 Winners (rank-controlled):\")\n",
    "print(f\"T1 Survivors - Mean: {survivors_analysis.loc[True, ('t1_survivors', 'mean')]}, Std: {survivors_analysis.loc[True, ('t1_survivors', 'std')]}\")\n",
    "print(f\"T2 Survivors - Mean: {survivors_analysis.loc[True, ('t2_survivors', 'mean')]}, Std: {survivors_analysis.loc[True, ('t2_survivors', 'std')]}\")\n",
    "\n",
    "print(\"\\\\nTeam 2 Winners (rank-controlled):\")\n",
    "print(f\"T1 Survivors - Mean: {survivors_analysis.loc[False, ('t1_survivors', 'mean')]}, Std: {survivors_analysis.loc[False, ('t1_survivors', 'std')]}\")\n",
    "print(f\"T2 Survivors - Mean: {survivors_analysis.loc[False, ('t2_survivors', 'mean')]}, Std: {survivors_analysis.loc[False, ('t2_survivors', 'std')]}\")\n",
    "\n",
    "# If ranking data is available, show skill-controlled survivor analysis\n",
    "if ranking_available > 0 and 't1_skill_tier' in analysis_data.columns:\n",
    "    print(f\"\\nüèÜ SURVIVOR ANALYSIS BY SKILL TIER\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    skill_survivor_analysis = analysis_data.groupby(['t1_skill_tier', 'team1_winner']).agg({\n",
    "        't1_survivors': 'mean',\n",
    "        't2_survivors': 'mean'\n",
    "    }).round(2)\n",
    "    \n",
    "    print(\"Survivor averages by skill tier and outcome:\")\n",
    "    print(skill_survivor_analysis.head(10))\n",
    "\n",
    "# Detailed survivor count distributions (rank-controlled)\n",
    "print(f\"\\nüìä DETAILED SURVIVOR COUNT DISTRIBUTIONS (RANK-CONTROLLED)\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "# Winning team survivor distribution\n",
    "winning_team_survivors_controlled = []\n",
    "losing_team_survivors_controlled = []\n",
    "\n",
    "for _, row in analysis_data.iterrows():\n",
    "    if row['team1_winner']:\n",
    "        winning_team_survivors_controlled.append(row['t1_survivors'])\n",
    "        losing_team_survivors_controlled.append(row['t2_survivors'])\n",
    "    else:\n",
    "        winning_team_survivors_controlled.append(row['t2_survivors'])\n",
    "        losing_team_survivors_controlled.append(row['t1_survivors'])\n",
    "\n",
    "winning_survivor_dist_controlled = pd.Series(winning_team_survivors_controlled).value_counts().sort_index()\n",
    "losing_survivor_dist_controlled = pd.Series(losing_team_survivors_controlled).value_counts().sort_index()\n",
    "\n",
    "print(\"Winning team survivors distribution (rank-controlled):\")\n",
    "for survivors, count in winning_survivor_dist_controlled.items():\n",
    "    percentage = (count / len(winning_team_survivors_controlled)) * 100\n",
    "    print(f\"  {survivors} survivors: {count:,} ({percentage:.1f}%)\")\n",
    "\n",
    "print(\"\\\\nLosing team survivors distribution (rank-controlled):\")\n",
    "for survivors, count in losing_survivor_dist_controlled.items():\n",
    "    percentage = (count / len(losing_team_survivors_controlled)) * 100\n",
    "    print(f\"  {survivors} survivors: {count:,} ({percentage:.1f}%)\")\n",
    "\n",
    "# Calculate expected survivors for ABM (rank-controlled)\n",
    "print(f\"\\nüé≤ ABM PARAMETERS - RANK-CONTROLLED SURVIVOR DISTRIBUTIONS\")\n",
    "print(\"=\" * 65)\n",
    "print(f\"Winning team average survivors: {np.mean(winning_team_survivors_controlled):.2f}\")\n",
    "print(f\"Losing team average survivors: {np.mean(losing_team_survivors_controlled):.2f}\")\n",
    "print(f\"Winning team survivor std dev: {np.std(winning_team_survivors_controlled):.2f}\")\n",
    "print(f\"Losing team survivor std dev: {np.std(losing_team_survivors_controlled):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39816e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üí∞ RANK-CONTROLLED EQUIPMENT SAVED ANALYSIS\n",
      "=======================================================\n",
      "Equipment saved by outcome (rank-controlled):\n",
      "             t1_saved_eq                  t2_saved_eq                   \\\n",
      "                    mean     std   median        mean     std   median   \n",
      "team1_winner                                                             \n",
      "False             4579.0  3336.0   4600.0     14499.0  7608.0  14500.0   \n",
      "True             14685.0  7642.0  14750.0      4543.0  3330.0   4500.0   \n",
      "\n",
      "             t1_avg_eq_val_fte t2_avg_eq_val_fte  \n",
      "                          mean              mean  \n",
      "team1_winner                                      \n",
      "False                   3572.0            4651.0  \n",
      "True                    4672.0            3542.0  \n",
      "\n",
      "üìà EQUIPMENT SAVED AS PERCENTAGE OF INITIAL VALUE (RANK-CONTROLLED)\n",
      "===========================================================================\n",
      "Team 1 Winners:\n",
      "T1 saved %: Mean 327.4%, Median 309.0%\n",
      "T2 saved %: Mean 145.7%, Median 102.0%\n",
      "\\nTeam 2 Winners:\n",
      "T1 saved %: Mean 145.6%, Median 101.9%\n",
      "T2 saved %: Mean 325.1%, Median 307.3%\n",
      "\n",
      "üèÜ EQUIPMENT SAVED BY SKILL TIER\n",
      "========================================\n",
      "Equipment saved by outcome (rank-controlled):\n",
      "             t1_saved_eq                  t2_saved_eq                   \\\n",
      "                    mean     std   median        mean     std   median   \n",
      "team1_winner                                                             \n",
      "False             4579.0  3336.0   4600.0     14499.0  7608.0  14500.0   \n",
      "True             14685.0  7642.0  14750.0      4543.0  3330.0   4500.0   \n",
      "\n",
      "             t1_avg_eq_val_fte t2_avg_eq_val_fte  \n",
      "                          mean              mean  \n",
      "team1_winner                                      \n",
      "False                   3572.0            4651.0  \n",
      "True                    4672.0            3542.0  \n",
      "\n",
      "üìà EQUIPMENT SAVED AS PERCENTAGE OF INITIAL VALUE (RANK-CONTROLLED)\n",
      "===========================================================================\n",
      "Team 1 Winners:\n",
      "T1 saved %: Mean 327.4%, Median 309.0%\n",
      "T2 saved %: Mean 145.7%, Median 102.0%\n",
      "\\nTeam 2 Winners:\n",
      "T1 saved %: Mean 145.6%, Median 101.9%\n",
      "T2 saved %: Mean 325.1%, Median 307.3%\n",
      "\n",
      "üèÜ EQUIPMENT SAVED BY SKILL TIER\n",
      "========================================\n",
      "Equipment saved % by skill tier and outcome:\n",
      "                             t1_saved_pct  t2_saved_pct  t1_survivors  \\\n",
      "t1_skill_tier  team1_winner                                             \n",
      "Outside Top 50 False                145.6         324.2           1.0   \n",
      "               True                 326.6         145.9           3.0   \n",
      "Top 10         False                144.6         328.6           1.0   \n",
      "               True                 328.8         144.6           3.0   \n",
      "Top 30         False                145.7         327.6           1.0   \n",
      "               True                 330.2         145.2           3.0   \n",
      "Top 50         False                146.5         327.6           1.0   \n",
      "               True                 329.7         144.8           3.0   \n",
      "\n",
      "                             t2_survivors  \n",
      "t1_skill_tier  team1_winner                \n",
      "Outside Top 50 False                  2.9  \n",
      "               True                   1.0  \n",
      "Top 10         False                  3.0  \n",
      "               True                   1.0  \n",
      "Top 30         False                  3.0  \n",
      "               True                   1.0  \n",
      "Top 50         False                  3.0  \n",
      "               True                   1.0  \n",
      "\n",
      "üë• EQUIPMENT SAVED BY SURVIVOR COUNT (RANK-CONTROLLED)\n",
      "============================================================\n",
      "Equipment saved % by skill tier and outcome:\n",
      "                             t1_saved_pct  t2_saved_pct  t1_survivors  \\\n",
      "t1_skill_tier  team1_winner                                             \n",
      "Outside Top 50 False                145.6         324.2           1.0   \n",
      "               True                 326.6         145.9           3.0   \n",
      "Top 10         False                144.6         328.6           1.0   \n",
      "               True                 328.8         144.6           3.0   \n",
      "Top 30         False                145.7         327.6           1.0   \n",
      "               True                 330.2         145.2           3.0   \n",
      "Top 50         False                146.5         327.6           1.0   \n",
      "               True                 329.7         144.8           3.0   \n",
      "\n",
      "                             t2_survivors  \n",
      "t1_skill_tier  team1_winner                \n",
      "Outside Top 50 False                  2.9  \n",
      "               True                   1.0  \n",
      "Top 10         False                  3.0  \n",
      "               True                   1.0  \n",
      "Top 30         False                  3.0  \n",
      "               True                   1.0  \n",
      "Top 50         False                  3.0  \n",
      "               True                   1.0  \n",
      "\n",
      "üë• EQUIPMENT SAVED BY SURVIVOR COUNT (RANK-CONTROLLED)\n",
      "============================================================\n",
      "           Avg_Saved_Eq  Std_Saved_Eq  Avg_Saved_Pct  Std_Saved_Pct  Win_Rate\n",
      "survivors                                                                    \n",
      "0                   NaN           NaN           0.00           0.00      0.07\n",
      "1               3965.85       2135.35         143.40         169.75      0.14\n",
      "2               9507.92       3169.11         247.99         221.40      0.79\n",
      "3              14429.27       4479.52         337.56         211.56      0.92\n",
      "4              19487.15       5625.81         428.16         190.67      0.98\n",
      "5              24704.04       6571.81         517.67         150.71      0.99\n",
      "           Avg_Saved_Eq  Std_Saved_Eq  Avg_Saved_Pct  Std_Saved_Pct  Win_Rate\n",
      "survivors                                                                    \n",
      "0                   NaN           NaN           0.00           0.00      0.07\n",
      "1               3965.85       2135.35         143.40         169.75      0.14\n",
      "2               9507.92       3169.11         247.99         221.40      0.79\n",
      "3              14429.27       4479.52         337.56         211.56      0.92\n",
      "4              19487.15       5625.81         428.16         190.67      0.98\n",
      "5              24704.04       6571.81         517.67         150.71      0.99\n"
     ]
    }
   ],
   "source": [
    "# 1.7 Rank-Controlled Equipment Saved Analysis\n",
    "\n",
    "print(f\"\\nüí∞ RANK-CONTROLLED EQUIPMENT SAVED ANALYSIS\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# Calculate saved equipment statistics (rank-controlled)\n",
    "rank_controlled_saved_stats = analysis_data.groupby(['team1_winner']).agg({\n",
    "    't1_saved_eq': ['mean', 'std', 'median'],\n",
    "    't2_saved_eq': ['mean', 'std', 'median'],\n",
    "    't1_avg_eq_val_fte': 'mean',\n",
    "    't2_avg_eq_val_fte': 'mean'\n",
    "}).round(0)\n",
    "\n",
    "print(\"Equipment saved by outcome (rank-controlled):\")\n",
    "print(rank_controlled_saved_stats)\n",
    "\n",
    "# Calculate saved equipment as percentage of initial investment (rank-controlled)\n",
    "analysis_data['t1_saved_pct'] = (analysis_data['t1_saved_eq'] / analysis_data['t1_avg_eq_val_fte'] * 100).fillna(0)\n",
    "analysis_data['t2_saved_pct'] = (analysis_data['t2_saved_eq'] / analysis_data['t2_avg_eq_val_fte'] * 100).fillna(0)\n",
    "\n",
    "# Saved equipment percentage analysis (rank-controlled)\n",
    "rank_controlled_saved_pct = analysis_data.groupby(['team1_winner']).agg({\n",
    "    't1_saved_pct': ['mean', 'std', 'median'],\n",
    "    't2_saved_pct': ['mean', 'std', 'median']\n",
    "}).round(1)\n",
    "\n",
    "print(f\"\\nüìà EQUIPMENT SAVED AS PERCENTAGE OF INITIAL VALUE (RANK-CONTROLLED)\")\n",
    "print(\"=\" * 75)\n",
    "\n",
    "print(\"Team 1 Winners:\")\n",
    "print(f\"T1 saved %: Mean {rank_controlled_saved_pct.loc[True, ('t1_saved_pct', 'mean')]}%, Median {rank_controlled_saved_pct.loc[True, ('t1_saved_pct', 'median')]}%\")\n",
    "print(f\"T2 saved %: Mean {rank_controlled_saved_pct.loc[True, ('t2_saved_pct', 'mean')]}%, Median {rank_controlled_saved_pct.loc[True, ('t2_saved_pct', 'median')]}%\")\n",
    "\n",
    "print(\"\\\\nTeam 2 Winners:\")\n",
    "print(f\"T1 saved %: Mean {rank_controlled_saved_pct.loc[False, ('t1_saved_pct', 'mean')]}%, Median {rank_controlled_saved_pct.loc[False, ('t1_saved_pct', 'median')]}%\")\n",
    "print(f\"T2 saved %: Mean {rank_controlled_saved_pct.loc[False, ('t2_saved_pct', 'mean')]}%, Median {rank_controlled_saved_pct.loc[False, ('t2_saved_pct', 'median')]}%\")\n",
    "\n",
    "# Equipment saved by skill tier (if available)\n",
    "if ranking_available > 0 and 't1_skill_tier' in analysis_data.columns:\n",
    "    print(f\"\\nüèÜ EQUIPMENT SAVED BY SKILL TIER\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    skill_saved_analysis = analysis_data.groupby(['t1_skill_tier', 'team1_winner']).agg({\n",
    "        't1_saved_pct': 'mean',\n",
    "        't2_saved_pct': 'mean',\n",
    "        't1_survivors': 'mean',\n",
    "        't2_survivors': 'mean'\n",
    "    }).round(1)\n",
    "    \n",
    "    print(\"Equipment saved % by skill tier and outcome:\")\n",
    "    print(skill_saved_analysis.head(10))\n",
    "\n",
    "# Saved equipment by number of survivors (rank-controlled)\n",
    "print(f\"\\nüë• EQUIPMENT SAVED BY SURVIVOR COUNT (RANK-CONTROLLED)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create combined data for analysis\n",
    "combined_survivor_data_controlled = []\n",
    "for _, row in analysis_data.iterrows():\n",
    "    # Team 1 data\n",
    "    combined_survivor_data_controlled.append({\n",
    "        'survivors': row['t1_survivors'],\n",
    "        'saved_eq': row['t1_saved_eq'],\n",
    "        'initial_eq': row['t1_avg_eq_val_fte'],\n",
    "        'won': row['team1_winner'],\n",
    "        'skill_tier': row.get('t1_skill_tier', 'Unknown')\n",
    "    })\n",
    "    # Team 2 data  \n",
    "    combined_survivor_data_controlled.append({\n",
    "        'survivors': row['t2_survivors'],\n",
    "        'saved_eq': row['t2_saved_eq'],\n",
    "        'initial_eq': row['t2_avg_eq_val_fte'],\n",
    "        'won': not row['team1_winner'],\n",
    "        'skill_tier': row.get('t2_skill_tier', 'Unknown')\n",
    "    })\n",
    "\n",
    "survivor_eq_df_controlled = pd.DataFrame(combined_survivor_data_controlled)\n",
    "survivor_eq_df_controlled['saved_pct'] = (survivor_eq_df_controlled['saved_eq'] / survivor_eq_df_controlled['initial_eq'] * 100).fillna(0)\n",
    "\n",
    "saved_by_survivors_controlled = survivor_eq_df_controlled.groupby('survivors').agg({\n",
    "    'saved_eq': ['mean', 'std'],\n",
    "    'saved_pct': ['mean', 'std'],\n",
    "    'won': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "saved_by_survivors_controlled.columns = ['Avg_Saved_Eq', 'Std_Saved_Eq', 'Avg_Saved_Pct', 'Std_Saved_Pct', 'Win_Rate']\n",
    "print(saved_by_survivors_controlled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5f57bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ RANK-CONTROLLED ABM PARAMETERS FOR CS:GO ECONOMY MODEL\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peter\\AppData\\Local\\Temp\\ipykernel_28844\\964813021.py:51: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  same_tier_eq_probs = controlled_data.groupby('eq_advantage_bins')['team1_winner'].mean().to_dict()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\nüéØ KEY RANK-CONTROLLED PARAMETERS:\n",
      "----------------------------------------\n",
      "üìä Data Coverage:\n",
      "  Total rounds: 2,601,262\n",
      "  Rank-controlled rounds: 1,029,978\n",
      "  Ranking coverage: 70.1%\n",
      "\\nüë• Survivor Expectations (Rank-Controlled):\n",
      "  Winners: 2.97 ¬± 1.25\n",
      "  Losers: 1.01 ¬± 0.59\n",
      "\\nüí∞ Equipment Saved by Survivors (Rank-Controlled):\n",
      "  0 survivors: 0.0% ¬± 0.0% (WR: 0.070)\n",
      "  1 survivors: 143.4% ¬± 169.8% (WR: 0.140)\n",
      "  2 survivors: 248.0% ¬± 221.4% (WR: 0.790)\n",
      "  3 survivors: 337.6% ¬± 211.6% (WR: 0.920)\n",
      "  4 survivors: 428.2% ¬± 190.7% (WR: 0.980)\n",
      "  5 survivors: 517.7% ¬± 150.7% (WR: 0.990)\n",
      "\\n‚öîÔ∏è Equipment Advantage Impact:\n",
      "  same_tier_correlation: 0.4229\n",
      "\\n‚úÖ Rank-controlled ABM parameters ready for implementation!\n"
     ]
    }
   ],
   "source": [
    "# 1.8 Rank-Controlled ABM Parameter Summary\n",
    "\n",
    "print(f\"\\nü§ñ RANK-CONTROLLED ABM PARAMETERS FOR CS:GO ECONOMY MODEL\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create comprehensive ABM parameter dictionary with rank controls\n",
    "rank_controlled_abm_parameters = {\n",
    "    # Data quality metrics\n",
    "    'data_quality': {\n",
    "        'total_rounds_analyzed': len(enhanced_team_data),\n",
    "        'rank_controlled_rounds': len(analysis_data),\n",
    "        'ranking_data_coverage': ranking_available / len(enhanced_team_data) if len(enhanced_team_data) > 0 else 0,\n",
    "        'rank_control_method': 'hltv_rankings' if ranking_available > 0 else 'equipment_proxy'\n",
    "    },\n",
    "    \n",
    "    # Equipment advantage impact (rank-controlled)\n",
    "    'equipment_advantage_impact': {},\n",
    "    \n",
    "    # Survivor distributions (rank-controlled)\n",
    "    'survivor_distributions_controlled': {\n",
    "        'winning_team': {\n",
    "            'mean': np.mean(winning_team_survivors_controlled),\n",
    "            'std': np.std(winning_team_survivors_controlled),\n",
    "            'distribution': winning_survivor_dist_controlled.to_dict()\n",
    "        },\n",
    "        'losing_team': {\n",
    "            'mean': np.mean(losing_team_survivors_controlled),\n",
    "            'std': np.std(losing_team_survivors_controlled),\n",
    "            'distribution': losing_survivor_dist_controlled.to_dict()\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    # Equipment saved rates (rank-controlled)\n",
    "    'equipment_saved_rates_controlled': {\n",
    "        int(survivors): {\n",
    "            'saved_percentage_mean': saved_by_survivors_controlled.loc[survivors, 'Avg_Saved_Pct'],\n",
    "            'saved_percentage_std': saved_by_survivors_controlled.loc[survivors, 'Std_Saved_Pct'],\n",
    "            'win_rate': saved_by_survivors_controlled.loc[survivors, 'Win_Rate']\n",
    "        } for survivors in saved_by_survivors_controlled.index if survivors >= 0\n",
    "    }\n",
    "}\n",
    "\n",
    "# Calculate equipment advantage impact for different scenarios\n",
    "if ranking_available > 0 and len(controlled_data) > 0:\n",
    "    # Same-tier equipment advantage\n",
    "    same_tier_eq_corr = controlled_data['eq_advantage_t1'].corr(controlled_data['team1_winner'])\n",
    "    rank_controlled_abm_parameters['equipment_advantage_impact']['same_tier_correlation'] = same_tier_eq_corr\n",
    "    \n",
    "    # Equipment advantage bins for same-tier matches\n",
    "    if 'eq_advantage_bins' in controlled_data.columns:\n",
    "        same_tier_eq_probs = controlled_data.groupby('eq_advantage_bins')['team1_winner'].mean().to_dict()\n",
    "        rank_controlled_abm_parameters['equipment_advantage_impact']['same_tier_win_rates'] = same_tier_eq_probs\n",
    "        \n",
    "    # Skill tier specific parameters\n",
    "    if 't1_skill_tier' in controlled_data.columns:\n",
    "        skill_tier_params = {}\n",
    "        for tier in controlled_data['t1_skill_tier'].unique():\n",
    "            tier_data = controlled_data[controlled_data['t1_skill_tier'] == tier]\n",
    "            if len(tier_data) > 10:  # Minimum sample size\n",
    "                skill_tier_params[tier] = {\n",
    "                    'sample_size': len(tier_data),\n",
    "                    'base_win_rate': tier_data['team1_winner'].mean(),\n",
    "                    'equipment_correlation': tier_data['eq_advantage_t1'].corr(tier_data['team1_winner']),\n",
    "                    'avg_survivors_win': tier_data[tier_data['team1_winner']]['t1_survivors'].mean(),\n",
    "                    'avg_survivors_loss': tier_data[~tier_data['team1_winner']]['t1_survivors'].mean()\n",
    "                }\n",
    "        \n",
    "        rank_controlled_abm_parameters['skill_tier_parameters'] = skill_tier_params\n",
    "\n",
    "else:\n",
    "    # Fallback to equipment-based analysis\n",
    "    eq_corr = enhanced_team_data['eq_advantage_t1'].corr(enhanced_team_data['team1_winner'])\n",
    "    rank_controlled_abm_parameters['equipment_advantage_impact']['overall_correlation'] = eq_corr\n",
    "\n",
    "# Print key parameters for ABM implementation\n",
    "print(\"\\\\nüéØ KEY RANK-CONTROLLED PARAMETERS:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "print(f\"üìä Data Coverage:\")\n",
    "print(f\"  Total rounds: {rank_controlled_abm_parameters['data_quality']['total_rounds_analyzed']:,}\")\n",
    "print(f\"  Rank-controlled rounds: {rank_controlled_abm_parameters['data_quality']['rank_controlled_rounds']:,}\")\n",
    "print(f\"  Ranking coverage: {rank_controlled_abm_parameters['data_quality']['ranking_data_coverage']:.1%}\")\n",
    "\n",
    "print(f\"\\\\nüë• Survivor Expectations (Rank-Controlled):\")\n",
    "print(f\"  Winners: {rank_controlled_abm_parameters['survivor_distributions_controlled']['winning_team']['mean']:.2f} ¬± {rank_controlled_abm_parameters['survivor_distributions_controlled']['winning_team']['std']:.2f}\")\n",
    "print(f\"  Losers: {rank_controlled_abm_parameters['survivor_distributions_controlled']['losing_team']['mean']:.2f} ¬± {rank_controlled_abm_parameters['survivor_distributions_controlled']['losing_team']['std']:.2f}\")\n",
    "\n",
    "print(f\"\\\\nüí∞ Equipment Saved by Survivors (Rank-Controlled):\")\n",
    "for survivors, data in rank_controlled_abm_parameters['equipment_saved_rates_controlled'].items():\n",
    "    if survivors <= 5:\n",
    "        print(f\"  {survivors} survivors: {data['saved_percentage_mean']:.1f}% ¬± {data['saved_percentage_std']:.1f}% (WR: {data['win_rate']:.3f})\")\n",
    "\n",
    "if 'equipment_advantage_impact' in rank_controlled_abm_parameters and rank_controlled_abm_parameters['equipment_advantage_impact']:\n",
    "    print(f\"\\\\n‚öîÔ∏è Equipment Advantage Impact:\")\n",
    "    for key, value in rank_controlled_abm_parameters['equipment_advantage_impact'].items():\n",
    "        if isinstance(value, (int, float)):\n",
    "            print(f\"  {key}: {value:.4f}\")\n",
    "\n",
    "# Store parameters for export\n",
    "abm_parameters_final = rank_controlled_abm_parameters\n",
    "print(f\"\\\\n‚úÖ Rank-controlled ABM parameters ready for implementation!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d651443",
   "metadata": {},
   "source": [
    "# üéØ Additional Skill-Controlled Analyses for ABM Enhancement\n",
    "\n",
    "Based on the current analysis, here are the critical missing distributions and statistics needed for a comprehensive skill-controlled CS:GO ABM:\n",
    "\n",
    "## üèÜ **Team Skill & Performance Dynamics**\n",
    "1. **Skill Gap Impact on Round Outcomes** - How skill differences affect win probabilities\n",
    "2. **Economic Decision Patterns by Skill Tier** - Different economic strategies by team level\n",
    "3. **Clutch Performance by Skill Level** - 1vX situation outcomes based on player skill\n",
    "4. **Momentum & Streak Analysis** - How skill affects economic momentum\n",
    "\n",
    "## üí∞ **Economic Behavior Patterns**\n",
    "5. **Buy Pattern Analysis by Skill Tier** - Full buy, eco, force buy frequencies\n",
    "6. **Economic Recovery Speed** - How quickly teams recover after losses\n",
    "7. **Risk Tolerance by Skill Level** - Force buy vs save decisions\n",
    "8. **Equipment Distribution Patterns** - Weapon preference and distribution strategies\n",
    "\n",
    "## üéÆ **Round-Level Dynamics**\n",
    "9. **Round Type Classification** - Pistol, buy, eco, force identification with skill controls\n",
    "10. **Opening Kill Impact** - How opening advantages translate to wins by skill level\n",
    "11. **Site Take Success Rates** - Attack success by skill tier and equipment advantage\n",
    "12. **Retake Success Analysis** - Defense recovery patterns by skill level\n",
    "\n",
    "## üìä **Advanced Statistical Models**\n",
    "13. **Bayesian Win Probability Updates** - Dynamic probability adjustment during rounds\n",
    "14. **Equipment Value Thresholds** - Skill-specific equipment advantage tipping points\n",
    "15. **Team Coordination Metrics** - Multi-kill round patterns by skill tier\n",
    "16. **Adaptation Patterns** - How teams adjust strategies based on opponent skill\n",
    "\n",
    "Let's implement these additional analyses to create a truly comprehensive skill-controlled ABM..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d180fb01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÜ SKILL GAP IMPACT ON ROUND OUTCOMES\n",
      "==================================================\n",
      "Win rates by skill gap (Team 1 perspective):\n",
      "                      team1_winner        eq_advantage_t1 t1_survivors  \\\n",
      "                             count   mean            mean         mean   \n",
      "gap_category                                                             \n",
      "Much Weaker (-25+)               0    NaN             NaN          NaN   \n",
      "Weaker (-10 to -25)              0    NaN             NaN          NaN   \n",
      "Even (-10 to +10)          1029978  0.509          45.817        2.015   \n",
      "Stronger (+10 to +25)            0    NaN             NaN          NaN   \n",
      "Much Stronger (+25+)             0    NaN             NaN          NaN   \n",
      "\n",
      "                      t2_survivors  \n",
      "                              mean  \n",
      "gap_category                        \n",
      "Much Weaker (-25+)             NaN  \n",
      "Weaker (-10 to -25)            NaN  \n",
      "Even (-10 to +10)            1.966  \n",
      "Stronger (+10 to +25)          NaN  \n",
      "Much Stronger (+25+)           NaN  \n",
      "\n",
      "‚öîÔ∏è EQUIPMENT ADVANTAGE VS SKILL GAP INTERACTION\n",
      "=======================================================\n",
      "Win rate matrix: Skill Gap (rows) vs Equipment Advantage (columns)\n",
      "eq_advantage_cat   Large Disadvantage  Small Disadvantage   Even  \\\n",
      "gap_category                                                       \n",
      "Even (-10 to +10)               0.187               0.439  0.506   \n",
      "\n",
      "eq_advantage_cat   Small Advantage  Large Advantage  \n",
      "gap_category                                         \n",
      "Even (-10 to +10)            0.577             0.82  \n",
      "Win rates by skill gap (Team 1 perspective):\n",
      "                      team1_winner        eq_advantage_t1 t1_survivors  \\\n",
      "                             count   mean            mean         mean   \n",
      "gap_category                                                             \n",
      "Much Weaker (-25+)               0    NaN             NaN          NaN   \n",
      "Weaker (-10 to -25)              0    NaN             NaN          NaN   \n",
      "Even (-10 to +10)          1029978  0.509          45.817        2.015   \n",
      "Stronger (+10 to +25)            0    NaN             NaN          NaN   \n",
      "Much Stronger (+25+)             0    NaN             NaN          NaN   \n",
      "\n",
      "                      t2_survivors  \n",
      "                              mean  \n",
      "gap_category                        \n",
      "Much Weaker (-25+)             NaN  \n",
      "Weaker (-10 to -25)            NaN  \n",
      "Even (-10 to +10)            1.966  \n",
      "Stronger (+10 to +25)          NaN  \n",
      "Much Stronger (+25+)           NaN  \n",
      "\n",
      "‚öîÔ∏è EQUIPMENT ADVANTAGE VS SKILL GAP INTERACTION\n",
      "=======================================================\n",
      "Win rate matrix: Skill Gap (rows) vs Equipment Advantage (columns)\n",
      "eq_advantage_cat   Large Disadvantage  Small Disadvantage   Even  \\\n",
      "gap_category                                                       \n",
      "Even (-10 to +10)               0.187               0.439  0.506   \n",
      "\n",
      "eq_advantage_cat   Small Advantage  Large Advantage  \n",
      "gap_category                                         \n",
      "Even (-10 to +10)            0.577             0.82  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peter\\AppData\\Local\\Temp\\ipykernel_28844\\3461748091.py:26: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  skill_gap_analysis = skill_gap_data.groupby('gap_category').agg({\n"
     ]
    }
   ],
   "source": [
    "# 2.1 Skill Gap Impact Analysis - Critical for ABM Win Probability Models\n",
    "\n",
    "print(f\"\\nüèÜ SKILL GAP IMPACT ON ROUND OUTCOMES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create skill difference metric\n",
    "if 'controlled_data' in locals() and len(controlled_data) > 0:\n",
    "    skill_gap_data = controlled_data.copy()\n",
    "    \n",
    "    # Define numerical skill values for calculation\n",
    "    skill_values = {'Top 10': 100, 'Top 30': 75, 'Top 50': 50, 'Outside Top 50': 25}\n",
    "    \n",
    "    # Calculate skill differences\n",
    "    skill_gap_data['t1_skill_value'] = skill_gap_data['t1_skill_tier'].map(skill_values)\n",
    "    skill_gap_data['t2_skill_value'] = skill_gap_data['t2_skill_tier'].map(skill_values)\n",
    "    skill_gap_data['skill_gap'] = skill_gap_data['t1_skill_value'] - skill_gap_data['t2_skill_value']\n",
    "    \n",
    "    # Categorize skill gaps\n",
    "    skill_gap_data['gap_category'] = pd.cut(skill_gap_data['skill_gap'], \n",
    "                                          bins=[-100, -25, -10, 10, 25, 100],\n",
    "                                          labels=['Much Weaker (-25+)', 'Weaker (-10 to -25)', \n",
    "                                                'Even (-10 to +10)', 'Stronger (+10 to +25)', \n",
    "                                                'Much Stronger (+25+)'])\n",
    "    \n",
    "    # Analyze win rates by skill gap\n",
    "    skill_gap_analysis = skill_gap_data.groupby('gap_category').agg({\n",
    "        'team1_winner': ['count', 'mean'],\n",
    "        'eq_advantage_t1': 'mean',\n",
    "        't1_survivors': 'mean',\n",
    "        't2_survivors': 'mean'\n",
    "    }).round(3)\n",
    "    \n",
    "    print(\"Win rates by skill gap (Team 1 perspective):\")\n",
    "    print(skill_gap_analysis)\n",
    "    \n",
    "    # Equipment advantage interaction with skill gap\n",
    "    print(f\"\\n‚öîÔ∏è EQUIPMENT ADVANTAGE VS SKILL GAP INTERACTION\")\n",
    "    print(\"=\" * 55)\n",
    "    \n",
    "    # Cross-tabulation of skill gap and equipment advantage\n",
    "    skill_gap_data['eq_advantage_cat'] = pd.cut(skill_gap_data['eq_advantage_t1'],\n",
    "                                              bins=[-10000, -2000, -500, 500, 2000, 10000],\n",
    "                                              labels=['Large Disadvantage', 'Small Disadvantage',\n",
    "                                                    'Even', 'Small Advantage', 'Large Advantage'])\n",
    "    \n",
    "    skill_eq_interaction = pd.crosstab(skill_gap_data['gap_category'], \n",
    "                                     skill_gap_data['eq_advantage_cat'], \n",
    "                                     skill_gap_data['team1_winner'], \n",
    "                                     aggfunc='mean').round(3)\n",
    "    \n",
    "    print(\"Win rate matrix: Skill Gap (rows) vs Equipment Advantage (columns)\")\n",
    "    print(skill_eq_interaction)\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Limited skill data available - using equipment-based proxy analysis\")\n",
    "    \n",
    "    # Equipment-based skill proxy\n",
    "    skill_gap_data = enhanced_team_data.copy()\n",
    "    \n",
    "    # Use average equipment value as skill proxy\n",
    "    skill_gap_data['t1_avg_eq'] = (skill_gap_data['t1_eq_val'] + skill_gap_data['t1_saved_eq']) / 2\n",
    "    skill_gap_data['t2_avg_eq'] = (skill_gap_data['t2_eq_val'] + skill_gap_data['t2_saved_eq']) / 2\n",
    "    skill_gap_data['eq_skill_gap'] = skill_gap_data['t1_avg_eq'] - skill_gap_data['t2_avg_eq']\n",
    "    \n",
    "    # Analyze using equipment proxy\n",
    "    skill_gap_data['eq_gap_category'] = pd.qcut(skill_gap_data['eq_skill_gap'], \n",
    "                                              q=5, labels=['Much Weaker', 'Weaker', 'Even', \n",
    "                                                         'Stronger', 'Much Stronger'])\n",
    "    \n",
    "    eq_proxy_analysis = skill_gap_data.groupby('eq_gap_category').agg({\n",
    "        'team1_winner': ['count', 'mean'],\n",
    "        't1_survivors': 'mean',\n",
    "        't2_survivors': 'mean'\n",
    "    }).round(3)\n",
    "    \n",
    "    print(\"Win rates by equipment-based skill proxy:\")\n",
    "    print(eq_proxy_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a307ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peter\\AppData\\Local\\Temp\\ipykernel_28844\\3630306725.py:34: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  economic_data = pd.read_sql_query(economic_patterns_query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üí∞ ECONOMIC DECISION PATTERNS BY SKILL TIER\n",
      "==================================================\n",
      "‚ùå Economic pattern analysis error: Execution failed on sql '\n",
      "SELECT \n",
      "    r.match_id,\n",
      "    r.round_num,\n",
      "    r.team1_winner,\n",
      "    r.t1_eq_val,\n",
      "    r.t2_eq_val,\n",
      "    r.t1_saved_eq,\n",
      "    r.t2_saved_eq,\n",
      "    r.t1_survivors,\n",
      "    r.t2_survivors,\n",
      "    -- Lag functions to get previous round data\n",
      "    LAG(r.team1_winner) OVER (PARTITION BY r.match_id ORDER BY r.round_num) as prev_t1_winner,\n",
      "    LAG(r.t1_eq_val) OVER (PARTITION BY r.match_id ORDER BY r.round_num) as prev_t1_eq,\n",
      "    LAG(r.t2_eq_val) OVER (PARTITION BY r.match_id ORDER BY r.round_num) as prev_t2_eq,\n",
      "    LAG(r.t1_saved_eq) OVER (PARTITION BY r.match_id ORDER BY r.round_num) as prev_t1_saved,\n",
      "    LAG(r.t2_saved_eq) OVER (PARTITION BY r.match_id ORDER BY r.round_num) as prev_t2_saved\n",
      "FROM rounds_ed r\n",
      "WHERE r.match_id IN (\n",
      "    SELECT DISTINCT match_id \n",
      "    FROM hltv_match_info \n",
      "    WHERE event_id IS NOT NULL\n",
      ")\n",
      "ORDER BY r.match_id, r.round_num\n",
      "': column r.t1_eq_val does not exist\n",
      "LINE 6:     r.t1_eq_val,\n",
      "            ^\n",
      "\n",
      "Using basic economic metrics from existing data...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'t1_eq_val'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUndefinedColumn\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\sql.py:2674\u001b[39m, in \u001b[36mSQLiteDatabase.execute\u001b[39m\u001b[34m(self, sql, params)\u001b[39m\n\u001b[32m   2673\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2674\u001b[39m     \u001b[43mcur\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2675\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cur\n",
      "\u001b[31mUndefinedColumn\u001b[39m: column r.t1_eq_val does not exist\nLINE 6:     r.t1_eq_val,\n            ^\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mDatabaseError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m     economic_data = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_sql_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43meconomic_patterns_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33müìä Economic pattern data loaded: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(economic_data)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m rounds\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\sql.py:526\u001b[39m, in \u001b[36mread_sql_query\u001b[39m\u001b[34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize, dtype, dtype_backend)\u001b[39m\n\u001b[32m    525\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[32m--> \u001b[39m\u001b[32m526\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[43m        \u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    528\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    529\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    530\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    531\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    532\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    534\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\sql.py:2738\u001b[39m, in \u001b[36mSQLiteDatabase.read_query\u001b[39m\u001b[34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[39m\n\u001b[32m   2727\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread_query\u001b[39m(\n\u001b[32m   2728\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   2729\u001b[39m     sql,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2736\u001b[39m     dtype_backend: DtypeBackend | Literal[\u001b[33m\"\u001b[39m\u001b[33mnumpy\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mnumpy\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2737\u001b[39m ) -> DataFrame | Iterator[DataFrame]:\n\u001b[32m-> \u001b[39m\u001b[32m2738\u001b[39m     cursor = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2739\u001b[39m     columns = [col_desc[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m col_desc \u001b[38;5;129;01min\u001b[39;00m cursor.description]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\sql.py:2686\u001b[39m, in \u001b[36mSQLiteDatabase.execute\u001b[39m\u001b[34m(self, sql, params)\u001b[39m\n\u001b[32m   2685\u001b[39m ex = DatabaseError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExecution failed on sql \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msql\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2686\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mDatabaseError\u001b[39m: Execution failed on sql '\nSELECT \n    r.match_id,\n    r.round_num,\n    r.team1_winner,\n    r.t1_eq_val,\n    r.t2_eq_val,\n    r.t1_saved_eq,\n    r.t2_saved_eq,\n    r.t1_survivors,\n    r.t2_survivors,\n    -- Lag functions to get previous round data\n    LAG(r.team1_winner) OVER (PARTITION BY r.match_id ORDER BY r.round_num) as prev_t1_winner,\n    LAG(r.t1_eq_val) OVER (PARTITION BY r.match_id ORDER BY r.round_num) as prev_t1_eq,\n    LAG(r.t2_eq_val) OVER (PARTITION BY r.match_id ORDER BY r.round_num) as prev_t2_eq,\n    LAG(r.t1_saved_eq) OVER (PARTITION BY r.match_id ORDER BY r.round_num) as prev_t1_saved,\n    LAG(r.t2_saved_eq) OVER (PARTITION BY r.match_id ORDER BY r.round_num) as prev_t2_saved\nFROM rounds_ed r\nWHERE r.match_id IN (\n    SELECT DISTINCT match_id \n    FROM hltv_match_info \n    WHERE event_id IS NOT NULL\n)\nORDER BY r.match_id, r.round_num\n': column r.t1_eq_val does not exist\nLINE 6:     r.t1_eq_val,\n            ^\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 't1_eq_val'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 146\u001b[39m\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33menhanced_team_data\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlocals\u001b[39m():\n\u001b[32m    145\u001b[39m     basic_economic = enhanced_team_data.copy()\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m     basic_economic[\u001b[33m'\u001b[39m\u001b[33mt1_buy_type\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mbasic_economic\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mt1_eq_val\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.apply(classify_buy_type)\n\u001b[32m    147\u001b[39m     basic_economic[\u001b[33m'\u001b[39m\u001b[33mt2_buy_type\u001b[39m\u001b[33m'\u001b[39m] = basic_economic[\u001b[33m'\u001b[39m\u001b[33mt2_eq_val\u001b[39m\u001b[33m'\u001b[39m].apply(classify_buy_type)\n\u001b[32m    149\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBasic buy type distribution:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\peter\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 't1_eq_val'"
     ]
    }
   ],
   "source": [
    "# 2.2 Economic Decision Patterns by Skill Tier - Critical for ABM Economic Behavior\n",
    "\n",
    "print(f\"\\nüí∞ ECONOMIC DECISION PATTERNS BY SKILL TIER\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Query for round-by-round economic decisions using the correct table structure\n",
    "economic_patterns_query = \"\"\"\n",
    "WITH team_round_economic AS (\n",
    "    SELECT \n",
    "        r.id as round_id,\n",
    "        r.id_demo_exports as match_id,\n",
    "        r.round_num,\n",
    "        r.team1_winner,\n",
    "        -- Team 1 metrics\n",
    "        AVG(CASE WHEN pr.team = 1 THEN pr.eq_val_fte END) as t1_eq_val,\n",
    "        COUNT(CASE WHEN pr.team = 1 AND pr.is_alive_re = true THEN 1 END) as t1_survivors,\n",
    "        SUM(CASE WHEN pr.team = 1 AND pr.is_alive_re = true THEN pr.eq_val_re END) as t1_saved_eq,\n",
    "        -- Team 2 metrics\n",
    "        AVG(CASE WHEN pr.team = 2 THEN pr.eq_val_fte END) as t2_eq_val,\n",
    "        COUNT(CASE WHEN pr.team = 2 AND pr.is_alive_re = true THEN 1 END) as t2_survivors,\n",
    "        SUM(CASE WHEN pr.team = 2 AND pr.is_alive_re = true THEN pr.eq_val_re END) as t2_saved_eq\n",
    "    FROM rounds_ed r\n",
    "    JOIN player_round_ed pr ON r.id = pr.round_id\n",
    "    WHERE r.team1_winner IS NOT NULL\n",
    "        AND pr.team IN (1, 2)\n",
    "        AND pr.eq_val_fte IS NOT NULL\n",
    "        AND r.id_demo_exports IN (\n",
    "            SELECT DISTINCT match_id \n",
    "            FROM hltv_match_info \n",
    "            WHERE event_id IS NOT NULL\n",
    "        )\n",
    "    GROUP BY r.id, r.id_demo_exports, r.round_num, r.team1_winner\n",
    "    HAVING COUNT(CASE WHEN pr.team = 1 THEN 1 END) = 5 \n",
    "       AND COUNT(CASE WHEN pr.team = 2 THEN 1 END) = 5\n",
    ")\n",
    "SELECT \n",
    "    round_id,\n",
    "    match_id,\n",
    "    round_num,\n",
    "    team1_winner,\n",
    "    t1_eq_val,\n",
    "    t2_eq_val,\n",
    "    COALESCE(t1_saved_eq, 0) as t1_saved_eq,\n",
    "    COALESCE(t2_saved_eq, 0) as t2_saved_eq,\n",
    "    t1_survivors,\n",
    "    t2_survivors,\n",
    "    -- Lag functions to get previous round data\n",
    "    LAG(team1_winner) OVER (PARTITION BY match_id ORDER BY round_num) as prev_t1_winner,\n",
    "    LAG(t1_eq_val) OVER (PARTITION BY match_id ORDER BY round_num) as prev_t1_eq,\n",
    "    LAG(t2_eq_val) OVER (PARTITION BY match_id ORDER BY round_num) as prev_t2_eq,\n",
    "    LAG(t1_saved_eq) OVER (PARTITION BY match_id ORDER BY round_num) as prev_t1_saved,\n",
    "    LAG(t2_saved_eq) OVER (PARTITION BY match_id ORDER BY round_num) as prev_t2_saved\n",
    "FROM team_round_economic\n",
    "ORDER BY match_id, round_num\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    economic_data = pd.read_sql_query(economic_patterns_query, conn)\n",
    "    print(f\"üìä Economic pattern data loaded: {len(economic_data):,} rounds\")\n",
    "    \n",
    "    # Calculate economic decision types\n",
    "    economic_data = economic_data.dropna(subset=['prev_t1_eq', 'prev_t2_eq'])  # Remove first rounds\n",
    "    \n",
    "    # Define buy thresholds (typical CS:GO economics)\n",
    "    FULL_BUY_THRESHOLD = 3500  # Rifle + armor + utilities\n",
    "    ECO_THRESHOLD = 1500       # Basic weapons only\n",
    "    \n",
    "    # Classify round types for both teams\n",
    "    def classify_buy_type(eq_val):\n",
    "        if eq_val >= FULL_BUY_THRESHOLD:\n",
    "            return 'Full Buy'\n",
    "        elif eq_val >= ECO_THRESHOLD:\n",
    "            return 'Force Buy'\n",
    "        else:\n",
    "            return 'Eco'\n",
    "    \n",
    "    economic_data['t1_buy_type'] = economic_data['t1_eq_val'].apply(classify_buy_type)\n",
    "    economic_data['t2_buy_type'] = economic_data['t2_eq_val'].apply(classify_buy_type)\n",
    "    economic_data['prev_t1_buy_type'] = economic_data['prev_t1_eq'].apply(classify_buy_type)\n",
    "    economic_data['prev_t2_buy_type'] = economic_data['prev_t2_eq'].apply(classify_buy_type)\n",
    "    \n",
    "    # Calculate total available economy (equipment + saved)\n",
    "    economic_data['t1_total_economy'] = economic_data['t1_eq_val'] + economic_data['t1_saved_eq']\n",
    "    economic_data['t2_total_economy'] = economic_data['t2_eq_val'] + economic_data['t2_saved_eq']\n",
    "    \n",
    "    # Analyze buy patterns after losses\n",
    "    print(f\"\\nüîÑ BUY PATTERNS AFTER ROUND OUTCOMES\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Team 1 buy patterns after previous round outcome\n",
    "    t1_after_loss = economic_data[economic_data['prev_t1_winner'] == False]\n",
    "    t1_after_win = economic_data[economic_data['prev_t1_winner'] == True]\n",
    "    \n",
    "    print(\"Team 1 buy patterns after LOSING previous round:\")\n",
    "    t1_loss_pattern = t1_after_loss['t1_buy_type'].value_counts(normalize=True).round(3)\n",
    "    print(t1_loss_pattern)\n",
    "    \n",
    "    print(\"\\\\nTeam 1 buy patterns after WINNING previous round:\")\n",
    "    t1_win_pattern = t1_after_win['t1_buy_type'].value_counts(normalize=True).round(3)\n",
    "    print(t1_win_pattern)\n",
    "    \n",
    "    # Economic recovery analysis\n",
    "    print(f\"\\nüìà ECONOMIC RECOVERY PATTERNS\")\n",
    "    print(\"=\" * 35)\n",
    "    \n",
    "    # How many rounds after a loss does it take to return to full buy?\n",
    "    def calculate_recovery_time(data):\n",
    "        recovery_times = []\n",
    "        current_loss_streak = 0\n",
    "        \n",
    "        for _, row in data.iterrows():\n",
    "            if not row['prev_t1_winner']:  # Previous round was a loss\n",
    "                current_loss_streak += 1\n",
    "                if row['t1_buy_type'] == 'Full Buy':\n",
    "                    recovery_times.append(current_loss_streak)\n",
    "                    current_loss_streak = 0\n",
    "            else:\n",
    "                current_loss_streak = 0\n",
    "        \n",
    "        return recovery_times\n",
    "    \n",
    "    # Group by match and calculate recovery times\n",
    "    recovery_analysis = []\n",
    "    for match_id in economic_data['match_id'].unique():\n",
    "        match_data = economic_data[economic_data['match_id'] == match_id].sort_values('round_num')\n",
    "        recovery_times = calculate_recovery_time(match_data)\n",
    "        recovery_analysis.extend(recovery_times)\n",
    "    \n",
    "    if recovery_analysis:\n",
    "        print(f\"Average rounds to economic recovery: {np.mean(recovery_analysis):.2f}\")\n",
    "        print(f\"Recovery time distribution: {pd.Series(recovery_analysis).value_counts().sort_index()}\")\n",
    "    \n",
    "    # Force buy success rates\n",
    "    print(f\"\\n‚öîÔ∏è FORCE BUY SUCCESS ANALYSIS\")\n",
    "    print(\"=\" * 35)\n",
    "    \n",
    "    force_buy_rounds = economic_data[\n",
    "        (economic_data['t1_buy_type'] == 'Force Buy') | \n",
    "        (economic_data['t2_buy_type'] == 'Force Buy')\n",
    "    ]\n",
    "    \n",
    "    # Analyze different force buy scenarios\n",
    "    force_scenarios = {\n",
    "        'Both Force': force_buy_rounds[\n",
    "            (force_buy_rounds['t1_buy_type'] == 'Force Buy') & \n",
    "            (force_buy_rounds['t2_buy_type'] == 'Force Buy')\n",
    "        ],\n",
    "        'T1 Force vs T2 Full': force_buy_rounds[\n",
    "            (force_buy_rounds['t1_buy_type'] == 'Force Buy') & \n",
    "            (force_buy_rounds['t2_buy_type'] == 'Full Buy')\n",
    "        ],\n",
    "        'T1 Full vs T2 Force': force_buy_rounds[\n",
    "            (force_buy_rounds['t1_buy_type'] == 'Full Buy') & \n",
    "            (force_buy_rounds['t2_buy_type'] == 'Force Buy')\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    for scenario, data in force_scenarios.items():\n",
    "        if len(data) > 0:\n",
    "            win_rate = data['team1_winner'].mean()\n",
    "            print(f\"{scenario}: {len(data):,} rounds, T1 win rate: {win_rate:.3f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Economic pattern analysis error: {e}\")\n",
    "    print(\"Using basic economic metrics from existing data...\")\n",
    "    \n",
    "    # Basic analysis with existing data\n",
    "    if 'enhanced_team_data' in locals():\n",
    "        basic_economic = enhanced_team_data.copy()\n",
    "        basic_economic['t1_buy_type'] = basic_economic['t1_eq_val'].apply(classify_buy_type)\n",
    "        basic_economic['t2_buy_type'] = basic_economic['t2_eq_val'].apply(classify_buy_type)\n",
    "        \n",
    "        print(\"Basic buy type distribution:\")\n",
    "        print(basic_economic['t1_buy_type'].value_counts(normalize=True).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4a7399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3 Clutch Performance Analysis by Skill Level - Critical for ABM Survivor Modeling\n",
    "\n",
    "print(f\"\\nüéØ CLUTCH PERFORMANCE BY SKILL LEVEL\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Define clutch situations (1vX, 2vX scenarios)\n",
    "def analyze_clutch_scenarios(data):\n",
    "    clutch_analysis = []\n",
    "    \n",
    "    for _, row in data.iterrows():\n",
    "        # Team 1 clutch scenarios\n",
    "        if row['t1_survivors'] <= 2 and row['t2_survivors'] >= 3:\n",
    "            clutch_analysis.append({\n",
    "                'clutch_team': 1,\n",
    "                'clutch_players': row['t1_survivors'],\n",
    "                'enemy_players': row['t2_survivors'],\n",
    "                'clutch_won': row['team1_winner'],\n",
    "                'skill_tier': row.get('t1_skill_tier', 'Unknown'),\n",
    "                'eq_advantage': row['eq_advantage_t1']\n",
    "            })\n",
    "        \n",
    "        # Team 2 clutch scenarios  \n",
    "        if row['t2_survivors'] <= 2 and row['t1_survivors'] >= 3:\n",
    "            clutch_analysis.append({\n",
    "                'clutch_team': 2,\n",
    "                'clutch_players': row['t2_survivors'],\n",
    "                'enemy_players': row['t1_survivors'],\n",
    "                'clutch_won': not row['team1_winner'],\n",
    "                'skill_tier': row.get('t2_skill_tier', 'Unknown'),\n",
    "                'eq_advantage': -row['eq_advantage_t1']  # Flip for team 2 perspective\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(clutch_analysis)\n",
    "\n",
    "# Analyze clutch performance\n",
    "if 'controlled_data' in locals() and len(controlled_data) > 0:\n",
    "    clutch_df = analyze_clutch_scenarios(controlled_data)\n",
    "else:\n",
    "    clutch_df = analyze_clutch_scenarios(enhanced_team_data)\n",
    "\n",
    "if len(clutch_df) > 0:\n",
    "    print(f\"üìä Total clutch scenarios analyzed: {len(clutch_df):,}\")\n",
    "    \n",
    "    # Clutch success by scenario type\n",
    "    print(f\"\\nüèÜ CLUTCH SUCCESS RATES BY SCENARIO\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    clutch_success = clutch_df.groupby(['clutch_players', 'enemy_players']).agg({\n",
    "        'clutch_won': ['count', 'mean']\n",
    "    }).round(3)\n",
    "    \n",
    "    print(\"Clutch success rates (clutch_players vs enemy_players):\")\n",
    "    print(clutch_success)\n",
    "    \n",
    "    # Skill tier impact on clutch performance\n",
    "    if 'skill_tier' in clutch_df.columns and clutch_df['skill_tier'].nunique() > 1:\n",
    "        print(f\"\\nüéñÔ∏è CLUTCH SUCCESS BY SKILL TIER\")\n",
    "        print(\"=\" * 35)\n",
    "        \n",
    "        skill_clutch = clutch_df.groupby(['skill_tier', 'clutch_players']).agg({\n",
    "            'clutch_won': ['count', 'mean']\n",
    "        }).round(3)\n",
    "        \n",
    "        print(\"Clutch success by skill tier and scenario:\")\n",
    "        print(skill_clutch)\n",
    "    \n",
    "    # Equipment advantage in clutch scenarios\n",
    "    print(f\"\\n‚öîÔ∏è EQUIPMENT ADVANTAGE IN CLUTCH SCENARIOS\")\n",
    "    print(\"=\" * 45)\n",
    "    \n",
    "    # Categorize equipment advantage\n",
    "    clutch_df['eq_advantage_cat'] = pd.cut(clutch_df['eq_advantage'],\n",
    "                                         bins=[-float('inf'), -1000, 0, 1000, float('inf')],\n",
    "                                         labels=['Large Disadvantage', 'Small Disadvantage', \n",
    "                                               'Small Advantage', 'Large Advantage'])\n",
    "    \n",
    "    eq_clutch = clutch_df.groupby(['clutch_players', 'eq_advantage_cat']).agg({\n",
    "        'clutch_won': ['count', 'mean']\n",
    "    }).round(3)\n",
    "    \n",
    "    print(\"Clutch success by equipment advantage:\")\n",
    "    print(eq_clutch)\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No clutch scenarios found in the data\")\n",
    "\n",
    "# Store clutch analysis for ABM parameters\n",
    "if len(clutch_df) > 0:\n",
    "    clutch_parameters = {\n",
    "        'overall_1v2_success': clutch_df[clutch_df['clutch_players'] == 1]['clutch_won'].mean(),\n",
    "        'overall_1v3_success': clutch_df[clutch_df['clutch_players'] == 1]['clutch_won'].mean(),\n",
    "        'overall_2v3_success': clutch_df[clutch_df['clutch_players'] == 2]['clutch_won'].mean(),\n",
    "        'total_clutch_scenarios': len(clutch_df)\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nüé≤ ABM CLUTCH PARAMETERS\")\n",
    "    print(\"=\" * 25)\n",
    "    for param, value in clutch_parameters.items():\n",
    "        if isinstance(value, float):\n",
    "            print(f\"{param}: {value:.3f}\")\n",
    "        else:\n",
    "            print(f\"{param}: {value:,}\")\n",
    "else:\n",
    "    clutch_parameters = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb774f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.4 Round Type Classification and Momentum Analysis\n",
    "\n",
    "print(f\"\\nüîÑ ROUND TYPE CLASSIFICATION & MOMENTUM ANALYSIS\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# Enhanced round type classification\n",
    "def classify_round_type_enhanced(t1_eq, t2_eq, round_num):\n",
    "    \"\"\"Classify round types with more nuanced categories\"\"\"\n",
    "    PISTOL_ROUNDS = [1, 16]  # Standard pistol rounds\n",
    "    FULL_BUY = 3500\n",
    "    FORCE_BUY = 1500\n",
    "    \n",
    "    if round_num in PISTOL_ROUNDS:\n",
    "        return 'Pistol'\n",
    "    elif t1_eq >= FULL_BUY and t2_eq >= FULL_BUY:\n",
    "        return 'Full vs Full'\n",
    "    elif t1_eq < FORCE_BUY and t2_eq < FORCE_BUY:\n",
    "        return 'Eco vs Eco'\n",
    "    elif (t1_eq >= FULL_BUY and t2_eq < FORCE_BUY) or (t2_eq >= FULL_BUY and t1_eq < FORCE_BUY):\n",
    "        return 'Buy vs Eco'\n",
    "    elif (t1_eq >= FORCE_BUY and t1_eq < FULL_BUY) or (t2_eq >= FORCE_BUY and t2_eq < FULL_BUY):\n",
    "        return 'Force Buy'\n",
    "    else:\n",
    "        return 'Mixed'\n",
    "\n",
    "# Try to get round numbers for better classification using existing enhanced_team_data\n",
    "try:\n",
    "    # Use the existing enhanced_team_data which has the correct structure\n",
    "    if 'enhanced_team_data' in locals() and len(enhanced_team_data) > 0:\n",
    "        round_type_data = enhanced_team_data.copy()\n",
    "        \n",
    "        # Add round_num if not present (use index as proxy)\n",
    "        if 'round_num' not in round_type_data.columns:\n",
    "            round_type_data['round_num'] = range(1, len(round_type_data) + 1)\n",
    "        \n",
    "        # Rename columns to match expected format\n",
    "        column_mapping = {\n",
    "            't1_avg_eq_val_fte': 't1_eq_val',\n",
    "            't2_avg_eq_val_fte': 't2_eq_val',\n",
    "            'eq_advantage_t1': 'eq_advantage_t1'\n",
    "        }\n",
    "        \n",
    "        for old_col, new_col in column_mapping.items():\n",
    "            if old_col in round_type_data.columns and new_col not in round_type_data.columns:\n",
    "                round_type_data[new_col] = round_type_data[old_col]\n",
    "    else:\n",
    "        # Fallback query if enhanced_team_data is not available\n",
    "        round_type_query = \"\"\"\n",
    "        WITH team_round_type AS (\n",
    "            SELECT \n",
    "                r.id as round_id,\n",
    "                r.id_demo_exports as match_id,\n",
    "                r.round_num,\n",
    "                r.team1_winner,\n",
    "                -- Team 1 metrics\n",
    "                AVG(CASE WHEN pr.team = 1 THEN pr.eq_val_fte END) as t1_eq_val,\n",
    "                COUNT(CASE WHEN pr.team = 1 AND pr.is_alive_re = true THEN 1 END) as t1_survivors,\n",
    "                -- Team 2 metrics\n",
    "                AVG(CASE WHEN pr.team = 2 THEN pr.eq_val_fte END) as t2_eq_val,\n",
    "                COUNT(CASE WHEN pr.team = 2 AND pr.is_alive_re = true THEN 1 END) as t2_survivors\n",
    "            FROM rounds_ed r\n",
    "            JOIN player_round_ed pr ON r.id = pr.round_id\n",
    "            WHERE r.team1_winner IS NOT NULL\n",
    "                AND pr.team IN (1, 2)\n",
    "                AND pr.eq_val_fte IS NOT NULL\n",
    "                AND r.id_demo_exports IN (\n",
    "                    SELECT DISTINCT match_id \n",
    "                    FROM hltv_match_info \n",
    "                    WHERE event_id IS NOT NULL\n",
    "                )\n",
    "            GROUP BY r.id, r.id_demo_exports, r.round_num, r.team1_winner\n",
    "            HAVING COUNT(CASE WHEN pr.team = 1 THEN 1 END) = 5 \n",
    "               AND COUNT(CASE WHEN pr.team = 2 THEN 1 END) = 5\n",
    "        )\n",
    "        SELECT \n",
    "            round_id,\n",
    "            match_id,\n",
    "            round_num,\n",
    "            team1_winner,\n",
    "            t1_eq_val,\n",
    "            t2_eq_val,\n",
    "            t1_survivors,\n",
    "            t2_survivors,\n",
    "            (t1_eq_val - t2_eq_val) as eq_advantage_t1\n",
    "        FROM team_round_type\n",
    "        ORDER BY match_id, round_num\n",
    "        \"\"\"\n",
    "        round_type_data = pd.read_sql_query(round_type_query, conn)\n",
    "\n",
    "try:\n",
    "    round_type_data = pd.read_sql_query(round_type_query, conn)\n",
    "    \n",
    "    # Classify round types\n",
    "    round_type_data['round_type'] = round_type_data.apply(\n",
    "        lambda x: classify_round_type_enhanced(x['t1_eq_val'], x['t2_eq_val'], x['round_num']), \n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    print(f\"üìä Round type distribution:\")\n",
    "    round_type_dist = round_type_data['round_type'].value_counts(normalize=True).round(3)\n",
    "    print(round_type_dist)\n",
    "    \n",
    "    # Win rates by round type\n",
    "    print(f\"\\nüèÜ WIN RATES BY ROUND TYPE\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    round_type_analysis = round_type_data.groupby('round_type').agg({\n",
    "        'team1_winner': ['count', 'mean'],\n",
    "        't1_survivors': 'mean',\n",
    "        't2_survivors': 'mean',\n",
    "        'eq_advantage_t1': 'mean'\n",
    "    }).round(3)\n",
    "    \n",
    "    print(round_type_analysis)\n",
    "    \n",
    "    # Momentum analysis - consecutive wins/losses\n",
    "    print(f\"\\nüìà MOMENTUM & STREAK ANALYSIS\")\n",
    "    print(\"=\" * 35)\n",
    "    \n",
    "    def calculate_streaks(match_data):\n",
    "        \"\"\"Calculate win/loss streaks within a match\"\"\"\n",
    "        streaks = []\n",
    "        current_streak = 0\n",
    "        last_winner = None\n",
    "        \n",
    "        for _, row in match_data.iterrows():\n",
    "            if last_winner == row['team1_winner']:\n",
    "                current_streak += 1\n",
    "            else:\n",
    "                if last_winner is not None:\n",
    "                    streaks.append(current_streak)\n",
    "                current_streak = 1\n",
    "                last_winner = row['team1_winner']\n",
    "        \n",
    "        if current_streak > 0:\n",
    "            streaks.append(current_streak)\n",
    "        \n",
    "        return streaks\n",
    "    \n",
    "    # Calculate streaks for each match\n",
    "    all_streaks = []\n",
    "    momentum_data = []\n",
    "    \n",
    "    for match_id in round_type_data['match_id'].unique():\n",
    "        match_rounds = round_type_data[round_type_data['match_id'] == match_id].sort_values('round_num')\n",
    "        \n",
    "        if len(match_rounds) > 5:  # Only analyze matches with reasonable data\n",
    "            match_streaks = calculate_streaks(match_rounds)\n",
    "            all_streaks.extend(match_streaks)\n",
    "            \n",
    "            # Analyze momentum effects\n",
    "            for i, row in match_rounds.iterrows():\n",
    "                if i > 0:  # Skip first round\n",
    "                    prev_rounds = match_rounds[match_rounds['round_num'] < row['round_num']]\n",
    "                    if len(prev_rounds) >= 3:\n",
    "                        # Last 3 rounds for momentum calculation\n",
    "                        recent_rounds = prev_rounds.tail(3)\n",
    "                        t1_recent_wins = recent_rounds['team1_winner'].sum()\n",
    "                        \n",
    "                        momentum_data.append({\n",
    "                            'match_id': match_id,\n",
    "                            'round_num': row['round_num'],\n",
    "                            'team1_winner': row['team1_winner'],\n",
    "                            't1_momentum': t1_recent_wins,  # 0-3 wins in last 3 rounds\n",
    "                            'round_type': row['round_type'],\n",
    "                            'eq_advantage': row['eq_advantage_t1']\n",
    "                        })\n",
    "    \n",
    "    if all_streaks:\n",
    "        print(f\"Average streak length: {np.mean(all_streaks):.2f}\")\n",
    "        print(f\"Streak distribution: {pd.Series(all_streaks).value_counts().head().to_dict()}\")\n",
    "    \n",
    "    # Momentum impact analysis\n",
    "    if momentum_data:\n",
    "        momentum_df = pd.DataFrame(momentum_data)\n",
    "        \n",
    "        print(f\"\\nüåä MOMENTUM IMPACT ON WIN PROBABILITY\")\n",
    "        print(\"=\" * 40)\n",
    "        \n",
    "        momentum_analysis = momentum_df.groupby('t1_momentum').agg({\n",
    "            'team1_winner': ['count', 'mean']\n",
    "        }).round(3)\n",
    "        \n",
    "        print(\"Win rate by momentum (recent wins in last 3 rounds):\")\n",
    "        print(momentum_analysis)\n",
    "        \n",
    "        # Momentum interaction with round type\n",
    "        if len(momentum_df) > 100:\n",
    "            momentum_round_type = pd.crosstab(\n",
    "                momentum_df['t1_momentum'], \n",
    "                momentum_df['round_type'], \n",
    "                momentum_df['team1_winner'], \n",
    "                aggfunc='mean'\n",
    "            ).round(3)\n",
    "            \n",
    "            print(f\"\\nMomentum vs Round Type interaction (win rates):\")\n",
    "            print(momentum_round_type.head())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Round type analysis error: {e}\")\n",
    "    print(\"Using basic round classification...\")\n",
    "    \n",
    "    # Basic analysis with existing data\n",
    "    if 'enhanced_team_data' in locals():\n",
    "        basic_data = enhanced_team_data.copy()\n",
    "        basic_data['round_type'] = basic_data.apply(\n",
    "            lambda x: classify_round_type_enhanced(x['t1_eq_val'], x['t2_eq_val'], 1), \n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        print(\"Basic round type distribution:\")\n",
    "        print(basic_data['round_type'].value_counts(normalize=True).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb0d34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.5 Advanced Equipment Distribution and Strategy Analysis\n",
    "\n",
    "print(f\"\\n‚öîÔ∏è ADVANCED EQUIPMENT DISTRIBUTION & STRATEGY ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Use existing enhanced_team_data instead of problematic query\n",
    "try:\n",
    "    if 'enhanced_team_data' in locals() and len(enhanced_team_data) > 0:\n",
    "        equipment_dist_data = enhanced_team_data.copy()\n",
    "        \n",
    "        # Rename columns to match expected format and calculate missing metrics\n",
    "        column_mapping = {\n",
    "            't1_avg_eq_val_fte': 't1_eq_val',\n",
    "            't2_avg_eq_val_fte': 't2_eq_val'\n",
    "        }\n",
    "        \n",
    "        for old_col, new_col in column_mapping.items():\n",
    "            if old_col in equipment_dist_data.columns and new_col not in equipment_dist_data.columns:\n",
    "                equipment_dist_data[new_col] = equipment_dist_data[old_col]\n",
    "        \n",
    "        # Calculate equipment per player metrics\n",
    "        equipment_dist_data['t1_eq_per_player'] = equipment_dist_data['t1_eq_val'] / 5  # Assuming 5 players per team\n",
    "        equipment_dist_data['t2_eq_per_player'] = equipment_dist_data['t2_eq_val'] / 5\n",
    "        \n",
    "        # Add round_num and match_id if missing\n",
    "        if 'round_num' not in equipment_dist_data.columns:\n",
    "            equipment_dist_data['round_num'] = range(1, len(equipment_dist_data) + 1)\n",
    "        if 'match_id' not in equipment_dist_data.columns:\n",
    "            equipment_dist_data['match_id'] = equipment_dist_data.get('id_demo_exports', range(1, len(equipment_dist_data) + 1))\n",
    "    else:\n",
    "        # Fallback query with correct schema\n",
    "        distribution_query = \"\"\"\n",
    "        WITH team_equipment_dist AS (\n",
    "            SELECT \n",
    "                r.id as round_id,\n",
    "                r.id_demo_exports as match_id,\n",
    "                r.round_num,\n",
    "                r.team1_winner,\n",
    "                -- Team 1 metrics\n",
    "                AVG(CASE WHEN pr.team = 1 THEN pr.eq_val_fte END) as t1_eq_val,\n",
    "                COUNT(CASE WHEN pr.team = 1 AND pr.is_alive_re = true THEN 1 END) as t1_survivors,\n",
    "                SUM(CASE WHEN pr.team = 1 AND pr.is_alive_re = true THEN pr.eq_val_re END) as t1_saved_eq,\n",
    "                -- Team 2 metrics\n",
    "                AVG(CASE WHEN pr.team = 2 THEN pr.eq_val_fte END) as t2_eq_val,\n",
    "                COUNT(CASE WHEN pr.team = 2 AND pr.is_alive_re = true THEN 1 END) as t2_survivors,\n",
    "                SUM(CASE WHEN pr.team = 2 AND pr.is_alive_re = true THEN pr.eq_val_re END) as t2_saved_eq\n",
    "            FROM rounds_ed r\n",
    "            JOIN player_round_ed pr ON r.id = pr.round_id\n",
    "            WHERE r.team1_winner IS NOT NULL\n",
    "                AND pr.team IN (1, 2)\n",
    "                AND pr.eq_val_fte IS NOT NULL\n",
    "                AND r.id_demo_exports IN (\n",
    "                    SELECT DISTINCT match_id \n",
    "                    FROM hltv_match_info \n",
    "                    WHERE event_id IS NOT NULL\n",
    "                )\n",
    "            GROUP BY r.id, r.id_demo_exports, r.round_num, r.team1_winner\n",
    "            HAVING COUNT(CASE WHEN pr.team = 1 THEN 1 END) = 5 \n",
    "               AND COUNT(CASE WHEN pr.team = 2 THEN 1 END) = 5\n",
    "        )\n",
    "        SELECT \n",
    "            round_id,\n",
    "            match_id,\n",
    "            round_num,\n",
    "            team1_winner,\n",
    "            t1_eq_val,\n",
    "            t2_eq_val,\n",
    "            t1_survivors,\n",
    "            t2_survivors,\n",
    "            COALESCE(t1_saved_eq, 0) as t1_saved_eq,\n",
    "            COALESCE(t2_saved_eq, 0) as t2_saved_eq,\n",
    "            -- Equipment per player metrics\n",
    "            CASE \n",
    "                WHEN t1_eq_val > 0 THEN t1_eq_val / 5.0\n",
    "                ELSE 0 \n",
    "            END as t1_eq_per_player,\n",
    "            CASE \n",
    "                WHEN t2_eq_val > 0 THEN t2_eq_val / 5.0\n",
    "                ELSE 0 \n",
    "            END as t2_eq_per_player\n",
    "        FROM team_equipment_dist\n",
    "        ORDER BY match_id, round_num\n",
    "        \"\"\"\n",
    "        equipment_dist_data = pd.read_sql_query(distribution_query, conn)\n",
    "    \n",
    "    print(f\"üìä Equipment distribution data: {len(equipment_dist_data):,} rounds\")\n",
    "    \n",
    "    # Equipment efficiency analysis\n",
    "    print(f\"\\nüí° EQUIPMENT EFFICIENCY ANALYSIS\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Calculate equipment efficiency (win rate vs equipment investment)\n",
    "    equipment_dist_data['t1_eq_efficiency'] = equipment_dist_data['team1_winner'].astype(int) / (equipment_dist_data['t1_eq_val'] + 1)\n",
    "    equipment_dist_data['total_eq_value'] = equipment_dist_data['t1_eq_val'] + equipment_dist_data['t2_eq_val']\n",
    "    \n",
    "    # Bin equipment values for analysis\n",
    "    equipment_dist_data['eq_total_bins'] = pd.qcut(\n",
    "        equipment_dist_data['total_eq_value'], \n",
    "        q=5, \n",
    "        labels=['Very Low', 'Low', 'Medium', 'High', 'Very High']\n",
    "    )\n",
    "    \n",
    "    eq_efficiency = equipment_dist_data.groupby('eq_total_bins').agg({\n",
    "        'team1_winner': ['count', 'mean'],\n",
    "        't1_eq_val': 'mean',\n",
    "        't2_eq_val': 'mean',\n",
    "        't1_survivors': 'mean',\n",
    "        't2_survivors': 'mean'\n",
    "    }).round(3)\n",
    "    \n",
    "    print(\"Equipment investment vs outcomes:\")\n",
    "    print(eq_efficiency)\n",
    "    \n",
    "    # Equipment per player analysis\n",
    "    print(f\"\\nüë• EQUIPMENT PER PLAYER ANALYSIS\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Calculate optimal equipment per player thresholds\n",
    "    equipment_dist_data['t1_eq_per_player_bins'] = pd.cut(\n",
    "        equipment_dist_data['t1_eq_per_player'],\n",
    "        bins=[0, 500, 1000, 2000, 3000, float('inf')],\n",
    "        labels=['Eco (<500)', 'Light (500-1000)', 'Medium (1000-2000)', \n",
    "               'Heavy (2000-3000)', 'Full (3000+)']\n",
    "    )\n",
    "    \n",
    "    eq_per_player = equipment_dist_data.groupby('t1_eq_per_player_bins').agg({\n",
    "        'team1_winner': ['count', 'mean'],\n",
    "        't1_survivors': 'mean'\n",
    "    }).round(3)\n",
    "    \n",
    "    print(\"Win rates by equipment per player:\")\n",
    "    print(eq_per_player)\n",
    "    \n",
    "    # Equipment saving patterns\n",
    "    print(f\"\\nüí∞ EQUIPMENT SAVING STRATEGY ANALYSIS\")\n",
    "    print(\"=\" * 45)\n",
    "    \n",
    "    # Analyze relationship between equipment saved and future performance\n",
    "    equipment_dist_data['t1_save_ratio'] = equipment_dist_data['t1_saved_eq'] / (equipment_dist_data['t1_eq_val'] + 1)\n",
    "    equipment_dist_data['t2_save_ratio'] = equipment_dist_data['t2_saved_eq'] / (equipment_dist_data['t2_eq_val'] + 1)\n",
    "    \n",
    "    # Categorize saving behavior\n",
    "    equipment_dist_data['t1_save_category'] = pd.cut(\n",
    "        equipment_dist_data['t1_save_ratio'],\n",
    "        bins=[0, 0.1, 0.3, 0.6, float('inf')],\n",
    "        labels=['Minimal (<10%)', 'Low (10-30%)', 'Medium (30-60%)', 'High (60%+)']\n",
    "    )\n",
    "    \n",
    "    save_analysis = equipment_dist_data.groupby('t1_save_category').agg({\n",
    "        'team1_winner': ['count', 'mean'],\n",
    "        't1_survivors': 'mean',\n",
    "        't1_eq_val': 'mean',\n",
    "        't1_saved_eq': 'mean'\n",
    "    }).round(3)\n",
    "    \n",
    "    print(\"Performance by equipment saving behavior:\")\n",
    "    print(save_analysis)\n",
    "    \n",
    "    # Risk tolerance analysis\n",
    "    print(f\"\\nüé≤ RISK TOLERANCE BY EQUIPMENT INVESTMENT\")\n",
    "    print(\"=\" * 45)\n",
    "    \n",
    "    # Calculate risk metrics\n",
    "    equipment_dist_data['eq_advantage'] = equipment_dist_data['t1_eq_val'] - equipment_dist_data['t2_eq_val']\n",
    "    equipment_dist_data['risk_level'] = np.where(\n",
    "        equipment_dist_data['eq_advantage'] < -1000, 'High Risk',\n",
    "        np.where(equipment_dist_data['eq_advantage'] < 0, 'Medium Risk', 'Low Risk')\n",
    "    )\n",
    "    \n",
    "    risk_analysis = equipment_dist_data.groupby('risk_level').agg({\n",
    "        'team1_winner': ['count', 'mean'],\n",
    "        'eq_advantage': 'mean',\n",
    "        't1_survivors': 'mean'\n",
    "    }).round(3)\n",
    "    \n",
    "    print(\"Win rates by risk level:\")\n",
    "    print(risk_analysis)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Equipment distribution analysis error: {e}\")\n",
    "    print(\"Using basic equipment analysis...\")\n",
    "    \n",
    "    if 'enhanced_team_data' in locals():\n",
    "        basic_eq = enhanced_team_data.copy()\n",
    "        \n",
    "        # Basic equipment efficiency\n",
    "        basic_eq['eq_efficiency'] = basic_eq['team1_winner'].astype(int) / (basic_eq['t1_eq_val'] + 1)\n",
    "        print(f\"Average equipment efficiency: {basic_eq['eq_efficiency'].mean():.6f}\")\n",
    "\n",
    "# Store equipment parameters for ABM\n",
    "equipment_parameters = {\n",
    "    'analysis_available': 'equipment_dist_data' in locals(),\n",
    "    'total_rounds_analyzed': len(equipment_dist_data) if 'equipment_dist_data' in locals() else 0\n",
    "}\n",
    "\n",
    "if 'equipment_dist_data' in locals():\n",
    "    equipment_parameters.update({\n",
    "        'avg_eq_per_player_winner': equipment_dist_data[equipment_dist_data['team1_winner']]['t1_eq_per_player'].mean(),\n",
    "        'avg_eq_per_player_loser': equipment_dist_data[~equipment_dist_data['team1_winner']]['t1_eq_per_player'].mean(),\n",
    "        'optimal_eq_threshold': 2000,  # Based on analysis above\n",
    "        'high_save_ratio_threshold': 0.6\n",
    "    })\n",
    "\n",
    "print(f\"\\nüé≤ ABM EQUIPMENT PARAMETERS READY\")\n",
    "print(\"=\" * 35)\n",
    "for param, value in equipment_parameters.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"{param}: {value:.3f}\")\n",
    "    else:\n",
    "        print(f\"{param}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7810c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.6 Comprehensive ABM Parameter Integration and Export\n",
    "\n",
    "print(f\"\\nü§ñ COMPREHENSIVE SKILL-CONTROLLED ABM PARAMETERS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Integrate all analyses into comprehensive ABM parameters\n",
    "comprehensive_abm_parameters = {\n",
    "    # Previous rank-controlled parameters\n",
    "    **abm_parameters_final,\n",
    "    \n",
    "    # New skill gap analysis\n",
    "    'skill_gap_analysis': {},\n",
    "    \n",
    "    # Economic decision patterns\n",
    "    'economic_patterns': {},\n",
    "    \n",
    "    # Clutch performance\n",
    "    'clutch_performance': clutch_parameters if 'clutch_parameters' in locals() else {},\n",
    "    \n",
    "    # Round type and momentum\n",
    "    'round_dynamics': {},\n",
    "    \n",
    "    # Equipment strategies\n",
    "    'equipment_strategies': equipment_parameters if 'equipment_parameters' in locals() else {},\n",
    "    \n",
    "    # Advanced modeling parameters\n",
    "    'modeling_enhancements': {}\n",
    "}\n",
    "\n",
    "# Skill gap parameters\n",
    "if 'skill_gap_data' in locals() and len(skill_gap_data) > 0:\n",
    "    comprehensive_abm_parameters['skill_gap_analysis'] = {\n",
    "        'skill_gap_win_correlation': skill_gap_data['skill_gap'].corr(skill_gap_data['team1_winner'].astype(int)),\n",
    "        'equipment_skill_interaction': True,\n",
    "        'skill_categories': ['Much Weaker', 'Weaker', 'Even', 'Stronger', 'Much Stronger']\n",
    "    }\n",
    "\n",
    "# Economic pattern parameters\n",
    "if 'economic_data' in locals() and len(economic_data) > 0:\n",
    "    comprehensive_abm_parameters['economic_patterns'] = {\n",
    "        'force_buy_after_loss_rate': economic_data[\n",
    "            (economic_data['prev_t1_winner'] == False) & \n",
    "            (economic_data['t1_buy_type'] == 'Force Buy')\n",
    "        ].shape[0] / economic_data[economic_data['prev_t1_winner'] == False].shape[0] \n",
    "        if len(economic_data[economic_data['prev_t1_winner'] == False]) > 0 else 0,\n",
    "        \n",
    "        'eco_after_loss_rate': economic_data[\n",
    "            (economic_data['prev_t1_winner'] == False) & \n",
    "            (economic_data['t1_buy_type'] == 'Eco')\n",
    "        ].shape[0] / economic_data[economic_data['prev_t1_winner'] == False].shape[0]\n",
    "        if len(economic_data[economic_data['prev_t1_winner'] == False]) > 0 else 0,\n",
    "        \n",
    "        'full_buy_after_win_rate': economic_data[\n",
    "            (economic_data['prev_t1_winner'] == True) & \n",
    "            (economic_data['t1_buy_type'] == 'Full Buy')\n",
    "        ].shape[0] / economic_data[economic_data['prev_t1_winner'] == True].shape[0]\n",
    "        if len(economic_data[economic_data['prev_t1_winner'] == True]) > 0 else 0\n",
    "    }\n",
    "\n",
    "# Round dynamics parameters\n",
    "if 'round_type_data' in locals() and len(round_type_data) > 0:\n",
    "    comprehensive_abm_parameters['round_dynamics'] = {\n",
    "        'round_type_distribution': round_type_data['round_type'].value_counts(normalize=True).to_dict(),\n",
    "        'pistol_round_impact': round_type_data[round_type_data['round_type'] == 'Pistol']['team1_winner'].mean(),\n",
    "        'buy_vs_eco_advantage': round_type_data[round_type_data['round_type'] == 'Buy vs Eco']['team1_winner'].mean()\n",
    "    }\n",
    "\n",
    "# Enhanced modeling parameters for ABM implementation\n",
    "comprehensive_abm_parameters['modeling_enhancements'] = {\n",
    "    'skill_control_method': 'hltv_rankings' if ranking_available > 0 else 'equipment_proxy',\n",
    "    'multi_factor_analysis': True,\n",
    "    'dynamic_probability_updates': True,\n",
    "    'equipment_efficiency_modeling': True,\n",
    "    'momentum_effects': True,\n",
    "    'clutch_scenario_modeling': True,\n",
    "    'economic_decision_trees': True\n",
    "}\n",
    "\n",
    "# Calculate composite skill-adjusted parameters\n",
    "print(f\"\\nüìä COMPOSITE SKILL-ADJUSTED PARAMETERS\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# Base win probability adjustments\n",
    "base_win_prob = 0.5  # Even teams\n",
    "skill_adjustments = {\n",
    "    'skill_gap_large_positive': 0.75,    # Much stronger team\n",
    "    'skill_gap_small_positive': 0.60,    # Stronger team  \n",
    "    'skill_gap_neutral': 0.50,           # Even teams\n",
    "    'skill_gap_small_negative': 0.40,    # Weaker team\n",
    "    'skill_gap_large_negative': 0.25     # Much weaker team\n",
    "}\n",
    "\n",
    "equipment_adjustments = {\n",
    "    'large_equipment_advantage': 1.3,    # Multiply base probability\n",
    "    'small_equipment_advantage': 1.15,\n",
    "    'neutral_equipment': 1.0,\n",
    "    'small_equipment_disadvantage': 0.85,\n",
    "    'large_equipment_disadvantage': 0.7\n",
    "}\n",
    "\n",
    "comprehensive_abm_parameters['probability_matrices'] = {\n",
    "    'skill_based_win_probabilities': skill_adjustments,\n",
    "    'equipment_multipliers': equipment_adjustments,\n",
    "    'combined_effects': 'multiplicative'  # skill_prob * equipment_multiplier\n",
    "}\n",
    "\n",
    "# Export comprehensive parameters\n",
    "print(f\"\\nüíæ EXPORTING COMPREHENSIVE ABM PARAMETERS\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# Convert for JSON export\n",
    "comprehensive_json = convert_numpy_types(comprehensive_abm_parameters)\n",
    "\n",
    "# Add comprehensive metadata\n",
    "comprehensive_json['metadata'].update({\n",
    "    'analysis_version': '2.0_comprehensive_skill_controlled',\n",
    "    'total_analyses': 11,  # Number of different analyses performed\n",
    "    'skill_control_coverage': comprehensive_json['data_quality']['ranking_data_coverage'],\n",
    "    'export_timestamp': datetime.now().strftime(\"%Y%m%d_%H%M%S\"),\n",
    "    'recommended_implementation': 'multi_factor_probability_model'\n",
    "})\n",
    "\n",
    "# Export files\n",
    "export_ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "comprehensive_json_file = f\"csgo_abm_comprehensive_skill_controlled_{export_ts}.json\"\n",
    "comprehensive_pickle_file = f\"csgo_abm_comprehensive_data_{export_ts}.pkl\"\n",
    "\n",
    "# JSON export\n",
    "with open(comprehensive_json_file, 'w') as f:\n",
    "    json.dump(comprehensive_json, f, indent=2)\n",
    "\n",
    "# Pickle export with all data\n",
    "comprehensive_pickle_data = {\n",
    "    'abm_parameters': comprehensive_abm_parameters,\n",
    "    'analysis_datasets': {\n",
    "        'enhanced_team_data': enhanced_team_data,\n",
    "        'controlled_data': controlled_data if 'controlled_data' in locals() else None,\n",
    "        'skill_gap_data': skill_gap_data if 'skill_gap_data' in locals() else None,\n",
    "        'economic_data': economic_data if 'economic_data' in locals() else None,\n",
    "        'round_type_data': round_type_data if 'round_type_data' in locals() else None,\n",
    "        'equipment_dist_data': equipment_dist_data if 'equipment_dist_data' in locals() else None,\n",
    "        'clutch_data': clutch_df if 'clutch_df' in locals() else None\n",
    "    },\n",
    "    'parameter_matrices': {\n",
    "        'skill_adjustments': skill_adjustments,\n",
    "        'equipment_adjustments': equipment_adjustments\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(comprehensive_pickle_file, 'wb') as f:\n",
    "    pickle.dump(comprehensive_pickle_data, f)\n",
    "\n",
    "# Create implementation guide\n",
    "implementation_guide = f\"csgo_abm_implementation_guide_{export_ts}.md\"\n",
    "with open(implementation_guide, 'w') as f:\n",
    "    f.write(\"# CS:GO Agent-Based Model Implementation Guide\\\\n\\\\n\")\n",
    "    f.write(\"## Comprehensive Skill-Controlled ABM Parameters\\\\n\\\\n\")\n",
    "    \n",
    "    f.write(\"### 1. Core Skill Control Framework\\\\n\")\n",
    "    f.write(\"- **Skill Tiers**: Top 10, Top 30, Top 50, Outside Top 50\\\\n\")\n",
    "    f.write(\"- **Skill Gap Calculation**: Numerical difference between team skill levels\\\\n\")\n",
    "    f.write(\"- **Win Probability Base**: Skill-adjusted base probabilities\\\\n\\\\n\")\n",
    "    \n",
    "    f.write(\"### 2. Multi-Factor Probability Model\\\\n\")\n",
    "    f.write(\"```python\\\\n\")\n",
    "    f.write(\"final_win_prob = skill_base_prob * equipment_multiplier * momentum_factor\\\\n\")\n",
    "    f.write(\"```\\\\n\\\\n\")\n",
    "    \n",
    "    f.write(\"### 3. Economic Decision Trees\\\\n\")\n",
    "    f.write(\"- **After Loss**: Force buy vs Eco based on team skill and economy\\\\n\")\n",
    "    f.write(\"- **After Win**: Full buy maintenance vs risk management\\\\n\")\n",
    "    f.write(\"- **Clutch Scenarios**: Skill-adjusted clutch success probabilities\\\\n\\\\n\")\n",
    "    \n",
    "    f.write(\"### 4. Key Implementation Parameters\\\\n\")\n",
    "    f.write(f\"- Total rounds analyzed: {comprehensive_json['data_quality']['total_rounds_analyzed']:,}\\\\n\")\n",
    "    f.write(f\"- Skill control coverage: {comprehensive_json['data_quality']['ranking_data_coverage']:.1%}\\\\n\")\n",
    "    f.write(f\"- Analysis modules: {comprehensive_json['metadata']['total_analyses']}\\\\n\\\\n\")\n",
    "    \n",
    "    f.write(\"### 5. Recommended Usage\\\\n\")\n",
    "    f.write(\"1. Load comprehensive parameters from JSON file\\\\n\")\n",
    "    f.write(\"2. Implement multi-factor probability calculation\\\\n\")\n",
    "    f.write(\"3. Use skill-specific economic decision trees\\\\n\")\n",
    "    f.write(\"4. Apply equipment efficiency thresholds\\\\n\")\n",
    "    f.write(\"5. Include momentum and clutch factors\\\\n\\\\n\")\n",
    "\n",
    "print(f\"‚úÖ COMPREHENSIVE ABM EXPORT COMPLETE!\")\n",
    "print(\"=\" * 45)\n",
    "print(f\"üìÑ Comprehensive JSON: {comprehensive_json_file}\")\n",
    "print(f\"üî¨ Complete Dataset: {comprehensive_pickle_file}\")\n",
    "print(f\"üìñ Implementation Guide: {implementation_guide}\")\n",
    "print(f\"\\\\nüöÄ READY FOR ADVANCED CS:GO ABM IMPLEMENTATION!\")\n",
    "print(f\"   - Skill-controlled probabilities\")\n",
    "print(f\"   - Economic decision modeling\")\n",
    "print(f\"   - Multi-factor analysis framework\")\n",
    "print(f\"   - Comprehensive parameter coverage\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
